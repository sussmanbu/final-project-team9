[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "Our dataset comes from IPUMS USA.\n\nReference: Steven Ruggles, Sarah Flood, Matthew Sobek, Daniel Backman, Annie Chen, Grace Cooper, Stephanie Richards, Renae Rodgers, and Megan Schouweiler. IPUMS USA: Version 15.0 [dataset]. Minneapolis, MN: IPUMS, 2024. https://doi.org/10.18128/D010.V15.0\n\nThe original data of this website came from censuses as well as the American Community Surveys (ACS) that began in 2000 and are still going on today. We chose our dataset from this website IPUMS because this website contains datasets that are large, valid and complex, containing detailed microdata, which aims to facilitate transformative research, education, and policy-making by aggregating data across times and places. It makes the datasets on this website very appropriate for our research to streamline our analysis of changes, data merging, and comparative research."
  },
  {
    "objectID": "data.html#describe-wherehow-to-find-data.",
    "href": "data.html#describe-wherehow-to-find-data.",
    "title": "Data",
    "section": "",
    "text": "Our dataset comes from IPUMS USA.\n\nReference: Steven Ruggles, Sarah Flood, Matthew Sobek, Daniel Backman, Annie Chen, Grace Cooper, Stephanie Richards, Renae Rodgers, and Megan Schouweiler. IPUMS USA: Version 15.0 [dataset]. Minneapolis, MN: IPUMS, 2024. https://doi.org/10.18128/D010.V15.0\n\nThe original data of this website came from censuses as well as the American Community Surveys (ACS) that began in 2000 and are still going on today. We chose our dataset from this website IPUMS because this website contains datasets that are large, valid and complex, containing detailed microdata, which aims to facilitate transformative research, education, and policy-making by aggregating data across times and places. It makes the datasets on this website very appropriate for our research to streamline our analysis of changes, data merging, and comparative research."
  },
  {
    "objectID": "data.html#describe-the-different-data-files-used-and-what-each-variable-means.",
    "href": "data.html#describe-the-different-data-files-used-and-what-each-variable-means.",
    "title": "Data",
    "section": "Describe the different data files used and what each variable means.",
    "text": "Describe the different data files used and what each variable means.\n\nTable contains all the variables we have\nWe have highlighted all key dependent variables (RENTGRS) and independent variables (INCTOT) in bold.\n\n\n\nVariable\nDescription\n\n\n\n\nRENTGRS\nMonthly gross rent\n\n\nKITCHEN\nKitchen or cooking facilities\n\n\nROOMS\nNumber of rooms\n\n\nNFAMS\nNumber of families in household\n\n\nAGE\nAge\n\n\nMARST\nMarital status\n\n\nRACE\nRace\n\n\nEMPSTAT\nEmployment status\n\n\nINCTOT\nTotal personal income\n\n\nFTOTINC\nTotal family income\n\n\nREGION\nGeographical part of America"
  },
  {
    "objectID": "data.html#describe-any-cleaning-you-had-to-do-for-your-data.",
    "href": "data.html#describe-any-cleaning-you-had-to-do-for-your-data.",
    "title": "Data",
    "section": "Describe any cleaning you had to do for your data.",
    "text": "Describe any cleaning you had to do for your data.\n\nHere is the link to our cleaned dataset cleaned dataset.\nThe code for cleaning and recoding the datasets, please see class blog 2 and 3.\nFor our dependent variable—rent—we exclude records indicating a rent of 0. This exclusion is based on the understanding that a 0 rent suggests the individual owns their home or lives in a situation not pertinent to our target research population, which is individuals who rent their housing.\nExclude data entries characterized by specific codes indicative of missing or unknown values, as well as those representing values deemed inappropriate for analytical purposes. The following table shows the variables we processed:\nGiven the vast size of the original dataset, which includes millions of records, we opted to remove these entries directly. This decision does not compromise our ability to conduct a thorough analysis, as the remaining dataset is still large and clean enough for reliable and robust research conclusions.\n\n\n\n\n\n\n\n\n\nVariable\nDescription\nNotes\n\n\n\n\nINCTOT\nTotal personal income\nSpecific codes detailed below:\n\n\n\n\n0000001 = $1 or break even (2000, 2005-onward ACS and PRCS)\n\n\n\n\n9999999 = N/A\n\n\n\n\n9999998 = Unknown\n\n\nFTOTINC\nTotal family income\nSpecific codes detailed below:\n\n\n\n\n-000001 = Net loss (1950)\n\n\n\n\n9999998 = Not ascertained (1950)\n\n\n\n\n9999999 = N/A\n\n\nKITCHEN\nKitchen or cooking facilities\n0 = N/A\n\n\nROOMS\nNumber of rooms\n00 = N/A\n\n\nEMPSTATA\nEmployment status\nSpecific codes detailed below:\n\n\n\n\n0 = Missing value\n\n\n\n\n9 = Unknown/Illegible\n\n\nSTATE\nGeographic state identifier\nSpecific codes detailed below:\n\n\n\n\n91 = Overseas Military/Military Installations\n\n\n\n\n92 = PUMA boundaries cross state lines - Metro sample\n\n\n\n\n97 = State not identified\n\n\n\n\n99 = Not identified\n\n\n\n\nRecode some categorical data that is showed in numerical value in our raw data.\n\nRecode certain variables. We modified certain variables in the dataset that are encoded with specific numerical codes, which reflect categories or qualitative information rather than quantitative values. The following table shows each variable that had been recoded; The detailed process of recoding is in Class blog3.\n\n\n\n\n\n\n\n\n\nVariable\nDescription\nNotes\n\n\n\n\nINCTOT\nTotal personal income\nSpecific codes detailed below:\n\n\n\n\n-009995 = -$9,900 (1980)\n\n\n\n\n-000001 = Net loss (1950)\n\n\n\n\nFTOTINC-000001 = Net loss (1950)\n\n\nKITCHEN\nKitchen facilities\n0 = N/A\n\n\n\n\n1 = No\n\n\n\n\n2 = No, or shared use\n\n\n\n\n3 = Yes, shared use\n\n\n\n\n4 = Yes (shared or exclusive use)\n\n\n\n\n5 = Yes, exclusive use\n\n\nMARST\nMarital status\n1 = Married, spouse present\n\n\n\n\n2 = Married, spouse absent\n\n\n\n\n3 = Separated\n\n\n\n\n4 = Divorced\n\n\n\n\n5 = Widowed\n\n\n\n\n6 = Never married/single\n\n\n\n\n9 = Blank, missing\n\n\nRACE\nRace\n1 = White\n\n\n\n\n2 = Black/African American\n\n\n\n\n3 = American Indian or Alaska Native\n\n\n\n\n4 = Chinese\n\n\n\n\n5 = Japanese\n\n\n\n\n6 = Other Asian or Pacific Islander\n\n\n\n\n7 = Other race, nec\n\n\n\n\n8 = Two major races\n\n\n\n\n9 = Three or more major races\n\n\nEMPSTAT\nEmployment status\n1 = Employed\n\n\n\n\n2 = Unemployed\n\n\n\n\n3 = Not in the labor force\n\n\nREGION\nGeographic region and division\nSpecific codes detailed below:\n\n\n\n\n11 = New England Division (Northeast)\n\n\n\n\n12 = Middle Atlantic Division (Northeast)\n\n\n\n\n13 = Mixed Northeast Divisions (Northeast)\n\n\n\n\n21 = East North Central Division (Midwest)\n\n\n\n\n22 = West North Central Division (Midwest)\n\n\n\n\n23 = Mixed Midwestern Divisions (Midwest)\n\n\n\n\n31 = South Atlantic Division (South)\n\n\n\n\n32 = East South Central Division (South)\n\n\n\n\n33 = West South Central Division (South)\n\n\n\n\n34 = Mixed Southern Divisions (South)\n\n\n\n\n41 = Mountain Division (West)\n\n\n\n\n42 = Pacific Division (West)\n\n\n\n\n43 = Mixed Western Divisions (West)\n\n\n\n\nMerged data\nWe consolidated datasets spanning 22 years, from 1990 to 2022, sourced from the same repositories. The approach to cleaning and processing these datasets was aligned with the methodology applied to the 2022 dataset, as previously detailed.\n\n\n\nSummary of numerical variables(2022)\n\n\n\n\n\n\n  \n    \n      Summary Statistics for Rental Data\n    \n    \n      Includes mean, median, minimum, and maximum values\n    \n    \n      Variable\n      Mean\n      Median\n      Minimum\n      Maximum\n    \n  \n  \n    RENTGRS\n1,572.82\n1,382.00\n4.00\n9,183.00\n    ROOMS\n4.69\n4.00\n1.00\n18.00\n    AGE\n42.73\n38.00\n16.00\n95.00\n    FTOTINC\n71,641.68\n52,000.00\n−1,730.00\n1,246,000.00\n    POVERTY\n268.95\n250.00\n1.00\n501.00\n    INCTOT\n38,115.39\n25,600.00\n−5,500.00\n791,000.00\n    NFAMS\n1.22\n1.00\n1.00\n20.00\n  \n  \n  \n\n\n\n\n\nSpeical notes to some variables we have\n\nRENTGRS\n\n\n\n\n\n\n-The histogram appears to be right-skewed, with a mode somewhere before $3000. It suggests that the mean is likely to be higher than the median, which corresponds to the stats in the above section. -There are a few bars past the $6000 mark, which could be considered outliers. -There’s a wide range of rents; however, the majority of the data points fall below $3000, suggesting that while there are rents across a wide range. -According to the right skewd nature, we take a log transformation to it in later on regression model.\n2.INCTOT\n\n\n\n\n\n\nThe histogram shows a very high peak at the lower end of the income range, suggest a right-skewed distribution. This suggests that a significant portion of the population earns within this lower income bracket. But it is what I expected because it’s the most common income range in the datasets and our dataset is from census.\n-According to the right skewd nature, we take a log transformation to it in later on regression model.\n\n3.FTOTINC\n\n\n\n\n\n\nSimliarly as the INCTOT, the histogram shows that the distribution of total family income is right-skewed, meaning most families have an income toward the lower end of the scale, with fewer families earning higher incomes. The tail might include outliers, which are families with significantly higher incomes than the typical family and the variance and standard deviation are likely to be large.\nThis variable shows to be related with INCTOT, we should test the multicollineaity issue while include it in our model.\nConsidering its nature and the possible multicollinearity issue, we plan to replace INCTOT to this variable to see if it suggests any change.\n\n4.NFAMS\n\n\n\n\n\nThe bar representing one family member is significantly taller than the others, indicating that single-person families are most common in this dataset. There is a rapid decrease in frequency as the number of family members increases. The families with a very large number of members are quite rare. This is what I expected and aligns with my understanding to common demographic trends."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "analysis.html#note-on-attribution",
    "href": "analysis.html#note-on-attribution",
    "title": "Analysis",
    "section": "Note on Attribution",
    "text": "Note on Attribution\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don’t have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don’t need a formal citation.\nIf you are directly quoting from a source, please make that clear. You can show quotes using &gt; like this\n&gt; To be or not to be.\n\nTo be or not to be."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 7, 2024 at 11:59pm.\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 7\n\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2024\n\n\nYating Zhu, Dingyu Guo, Suh Edwin Jiho, Wang Muxi\n\n\n\n\n\n\n  \n\n\n\n\nClass blog 6\n\n\n\n\n\n\n\n\n\n\n\n\nApr 17, 2024\n\n\nYating Zhu\n\n\n\n\n\n\n  \n\n\n\n\nClass blog 5\n\n\nMergede dataset\n\n\n\n\n\n\n\n\n\nApr 12, 2024\n\n\nYating Zhu, Dingyu Guo, Suh Edwin Jiho, Wang Muxi\n\n\n\n\n\n\n  \n\n\n\n\nClass blog 4\n\n\n\n\n\n\n\n\n\n\n\n\nMar 30, 2024\n\n\nYating Zhu, Dingyu Guo, Suh Edwin Jiho, Wang Muxi\n\n\n\n\n\n\n  \n\n\n\n\nClass blog3\n\n\nDataset and Description 2\n\n\n\n\n\n\n\n\n\nMar 26, 2024\n\n\nYating Zhu, Dingyu Guo, Suh Edwin Jiho, Wang Muxi\n\n\n\n\n\n\n  \n\n\n\n\nClass Blog 2\n\n\nDataset and Description\n\n\n\n\n\n\n\n\n\nMar 23, 2024\n\n\nYating Zhu, Dingyu Guo, Suh Edwin Jiho, Wang Muxi\n\n\n\n\n\n\n  \n\n\n\n\nClass Blog 1\n\n\nThree datasets proposed for final project\n\n\n\n\n\n\n\n\n\nMar 3, 2024\n\n\nYating Zhu, Dingyu Guo, Suh Edwin Jiho, Wang Muxi\n\n\n\n\n\n\n  \n\n\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n  \n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post.\n\n\n\n\n\n\nFeb 23, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n  \n\n\n\n\nfirst post\n\n\nfirst post\n\n\nHello, world\n\n\n\n\n\n\nFeb 23, 2024\n\n\nYating Zhu, Suh Edwin Jiho, Guo Xinyu, Wang Muxi,\n\n\n\n\n\n\n  \n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting.\n\n\n\n\n\n\nFeb 21, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-04-17-class-blog-6/class-blog-6.html",
    "href": "posts/2024-04-17-class-blog-6/class-blog-6.html",
    "title": "Class blog 6",
    "section": "",
    "text": "Confirmed that RACE is a factor and has at least two levels.\n\n\nIdentifying and removing groups where any of the specified categorical variables have only one level within each racial category, potentially indicating insufficient variability for statistical analysis.\n\n\n\n[1] Japanese\n9 Levels: American Indian or Alaska Native Black/African American ... White\n\n\n\nTable shows the coefficient of each races to the key predictor\n\n\n\n\n\n\nRACE\nlog_INCTOT_Coefficient\n\n\n\n\nAmerican Indian or Alaska Native\n0.0937685\n\n\nBlack/African American\n0.0621126\n\n\nChinese\n0.1915177\n\n\nOther Asian or Pacific Islander\n0.1050231\n\n\nOther race, nec\n0.0376731\n\n\nThree or more major races\n0.1048730\n\n\nTwo major races\n0.0882288\n\n\nWhite\n0.1676538\n\n\n\n\n\nAnalysis to the table: - The Chinese group exhibits the highest log_INCTOT coefficient, indicating the strongest positive association between income and the variable of interest in this dataset.\n\nAmerican Indian or Alaska Native, Other Asian or Pacific Islander, Other race, nec, Three or more major races, and White categories display coefficients ranging from approximately 0.0376 to 0.1676, suggesting varied degrees of positive association between income and the variable measured.\nThe Black/African American and Two major races groups have relatively lower coefficients of approximately 0.0621 and 0.0882, respectively, implying a weaker positive relationship compared to the other groups.\nThere is no negative coefficient present, which would indicate a negative relationship between income and the variable; all listed races have positive coefficients, implying a positive relationship across the board.\n\n\n\n\n\n\n\n\nConfimed that RACE is a factor and has at least two levels.\n\n\ndata_twenty$RACE &lt;- factor(data_twenty$RACE)\nif (length(levels(data_twenty$RACE)) &lt; 2) {\n  stop(\"RACE must have at least two levels\")\n}\n\n\nNo need to drop because all has more than one level.\n\n\n# Convert categorical variables to factors\ncategorical_vars &lt;- c(\"KITCHEN\", \"MARST\", \"EMPSTAT\", \"REGION_CLASSIFIED\")\ndata_twenty[categorical_vars] &lt;- lapply(data_twenty[categorical_vars], factor)\n\n# Convert categorical variables to factors\ncategorical_vars &lt;- c(\"KITCHEN\", \"MARST\", \"EMPSTAT\", \"REGION_CLASSIFIED\")\ndata_twenty[categorical_vars] &lt;- lapply(data_twenty[categorical_vars], factor)\n\n# Check the number of levels per categorical variable within each RACE group\nrace_levels &lt;- data_twenty %&gt;%\n  group_by(RACE) %&gt;%\n  summarize(across(all_of(categorical_vars), ~n_distinct(.))) %&gt;%\n  ungroup()\n\n# Identify RACE groups with any categorical variable having only one level\nraces_with_single_levels &lt;- race_levels %&gt;%\n  filter(if_any(everything(), ~.x == 1)) %&gt;%\n  pull(RACE) # Extract the RACE values with problematic levels\n\n# Filter out the problematic RACE groups from the main dataset\ndata_twenty_filtered &lt;- data_twenty %&gt;%\n  filter(!RACE %in% races_with_single_levels)\nprint(races_with_single_levels)\n\nfactor()\n9 Levels: American Indian or Alaska Native Black/African American ... White\n\n\n\n# Convert categorical variables to factors again after subsetting just in case\ndata_twenty_filtered[categorical_vars] &lt;- lapply(data_twenty_filtered[categorical_vars], factor)\n\n# Check the number of levels per categorical variable within each RACE-YEAR group\nrace_year_levels &lt;- data_twenty_filtered %&gt;%\n  group_by(RACE, YEAR) %&gt;%\n  summarize(across(all_of(categorical_vars), ~n_distinct(.))) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'RACE'. You can override using the\n`.groups` argument.\n\n# Identify RACE-YEAR groups with any categorical variable having only one level\nrace_year_with_single_levels &lt;- race_year_levels %&gt;%\n  filter(if_any(everything(), ~.x == 1)) \n\n# Display the RACE-YEAR groups with issues, if any\nprint(race_year_with_single_levels)\n\n# A tibble: 58 × 6\n   RACE                             YEAR KITCHEN MARST EMPSTAT REGION_CLASSIFIED\n   &lt;fct&gt;                           &lt;dbl&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt;             &lt;int&gt;\n 1 American Indian or Alaska Nati…  2000       1     2       3                 4\n 2 American Indian or Alaska Nati…  2002       1     4       3                 4\n 3 American Indian or Alaska Nati…  2003       1     4       3                 4\n 4 American Indian or Alaska Nati…  2004       1     4       3                 3\n 5 American Indian or Alaska Nati…  2006       1     6       3                 4\n 6 American Indian or Alaska Nati…  2010       1     5       3                 4\n 7 American Indian or Alaska Nati…  2019       1     5       3                 4\n 8 Black/African American           2001       1     6       3                 4\n 9 Chinese                          2000       1     3       2                 3\n10 Chinese                          2002       1     4       3                 3\n# ℹ 48 more rows\n\n\n\n# Filter out the problematic RACE-YEAR groups from the main dataset\ndata_twenty_filtered_final &lt;- data_twenty_filtered %&gt;%\n  anti_join(race_year_with_single_levels, by = c(\"RACE\", \"YEAR\"))\n\n\n# Now, with the cleaned data, fit the models\nmodels_by_race_year &lt;- data_twenty_filtered_final %&gt;%\n  group_by(RACE, YEAR) %&gt;%\n  do(\n    model = lm(log_RENTGRS ~ log_INCTOT + KITCHEN + ROOMS + NFAMS + AGE + MARST + EMPSTAT + REGION_CLASSIFIED, data = .)\n  )\n\n\nmodels_with_coef &lt;- models_by_race_year %&gt;%\n  rowwise() %&gt;% \n  mutate(log_INCTOT_coef = coef(model)[[\"log_INCTOT\"]]) %&gt;%\n  ungroup() %&gt;%\n  select(RACE, YEAR, log_INCTOT_coef)\n\ncoefficients_wide &lt;- models_with_coef %&gt;%\n  pivot_wider(names_from = RACE, values_from = log_INCTOT_coef, names_prefix = \"coef_\")\n\nkable(coefficients_wide)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYEAR\ncoef_American Indian or Alaska Native\ncoef_Black/African American\ncoef_Chinese\ncoef_Japanese\ncoef_Other Asian or Pacific Islander\ncoef_Other race, nec\ncoef_Three or more major races\ncoef_Two major races\ncoef_White\n\n\n\n\n2001\n0.0044494\nNA\n0.0097707\nNA\n0.1221862\n0.0818381\nNA\n0.1007001\n0.1445229\n\n\n2005\n-0.1728914\n0.0873527\n0.1326179\nNA\n0.0897322\n0.0429701\nNA\nNA\n0.1379574\n\n\n2007\n0.1239418\n0.1115806\nNA\nNA\n0.0864570\n0.1019018\nNA\n0.0988822\n0.1401784\n\n\n2008\n0.1662273\n0.0717442\nNA\nNA\n0.0495650\n0.0811385\nNA\n0.0705536\n0.1261771\n\n\n2009\n-0.0290841\n0.0982650\n0.0462740\nNA\n0.0979882\n0.1357880\nNA\n0.0883666\n0.1215903\n\n\n2011\n-0.0246266\n0.1289264\n0.1080701\n-0.3049829\n0.1056626\n0.0704745\nNA\n0.0950769\n0.1434630\n\n\n2012\n0.0829896\n0.0815911\n0.1408589\n0.2402733\n0.0947194\n0.0336927\nNA\n0.0447647\n0.1477391\n\n\n2013\n0.1450099\n0.1208850\nNA\n0.3074672\n0.0719337\n0.0944647\nNA\n0.1077284\n0.1413223\n\n\n2014\n-0.0806190\n0.0774011\n0.1243816\n0.1948937\n0.1704745\n0.0192973\n-0.0246775\n0.0501507\n0.1423022\n\n\n2015\n0.2288886\n0.0866523\n0.1437636\nNA\n0.0588220\n0.0124419\n-0.0798592\n0.0240695\n0.1366126\n\n\n2016\n0.0724100\n0.1070357\n0.0935354\nNA\n0.0892159\n0.0831495\nNA\n0.1105840\n0.1281357\n\n\n2017\n0.1140436\n0.1154084\n0.0120262\n0.0758910\n0.0610027\n0.1443399\nNA\n0.0379656\n0.1514833\n\n\n2018\n0.1443089\n0.1216139\n0.2833792\nNA\n0.1070153\n0.0425257\n0.3835364\n0.1375949\n0.1594088\n\n\n2020\n0.0264148\n0.0821522\n0.0947932\nNA\n0.1345643\n0.1008466\nNA\n0.0531118\n0.1628788\n\n\n2021\n-0.0599569\n0.0664240\n0.1149156\nNA\n0.1242797\n0.0334209\n-0.0382770\n0.0856113\n0.1649109\n\n\n2022\n0.0984965\n0.0632937\n0.2196783\nNA\n0.1033151\n0.0390094\n0.0722550\n0.0800541\n0.1637250\n\n\n2000\nNA\n0.0358345\nNA\nNA\nNA\nNA\nNA\nNA\n0.1459856\n\n\n2002\nNA\n0.0994888\nNA\nNA\nNA\n0.1131498\nNA\nNA\n0.1290758\n\n\n2003\nNA\n0.1201889\nNA\nNA\n0.0611945\n0.0426896\nNA\n-0.0781177\n0.1278780\n\n\n2004\nNA\n0.1245230\n0.0048313\nNA\n0.0655594\nNA\nNA\n0.0013052\n0.1292762\n\n\n2006\nNA\n0.1192481\n0.0993890\n0.4505390\n0.1058852\n0.0840827\nNA\nNA\n0.1273188\n\n\n2010\nNA\n0.0965021\nNA\n-0.8670287\n0.1104422\n0.0597122\nNA\n0.0686506\n0.1432963\n\n\n2019\nNA\n0.1027066\n0.2814538\nNA\n0.1331487\n0.0892457\nNA\nNA\n0.1464698\n\n\n\n\n\n\nSpecific Trends:\n\nAlaska Native: Shows minor fluctuations around zero, with both positive and negative coefficients, indicating inconsistent trends over the years.\nAmerican: This category has NA values, suggesting incomplete data, making it hard to discern a clear trend.\nChinese: Generally has higher positive coefficients compared to other groups, particularly noticeable in later years, indicating a strong positive association with income in those years.\nJapanese: Has some missing values but otherwise presents mostly positive coefficients, with a notable spike in recent years.\nIslander: Also features both positive and negative coefficients with considerable variability.\nOther race, nec: Shows a mix of positive, negative, and NA values, making a clear trend difficult to establish.\nTwo or more races: This group generally has positive coefficients, with a few exceptions, suggesting a fairly consistent positive association with income.\nWhites: Present a range of coefficients, mostly positive with some fluctuations, but generally indicate a positive association with income.\n\nRace Comparisons: Certain racial categories, like those identifying as Chinese and Japanese, tend to have higher coefficients, suggesting a stronger relationship with income than other races in the dataset. Conversely, the ‘Other race, nec’ category often has lower coefficients, implying a weaker association with income."
  },
  {
    "objectID": "posts/2024-04-17-class-blog-6/class-blog-6.html#group-by-race-see-coefficients-changes-over-years-and-races",
    "href": "posts/2024-04-17-class-blog-6/class-blog-6.html#group-by-race-see-coefficients-changes-over-years-and-races",
    "title": "Class blog 6",
    "section": "",
    "text": "Confirmed that RACE is a factor and has at least two levels.\n\n\nIdentifying and removing groups where any of the specified categorical variables have only one level within each racial category, potentially indicating insufficient variability for statistical analysis.\n\n\n\n[1] Japanese\n9 Levels: American Indian or Alaska Native Black/African American ... White\n\n\n\nTable shows the coefficient of each races to the key predictor\n\n\n\n\n\n\nRACE\nlog_INCTOT_Coefficient\n\n\n\n\nAmerican Indian or Alaska Native\n0.0937685\n\n\nBlack/African American\n0.0621126\n\n\nChinese\n0.1915177\n\n\nOther Asian or Pacific Islander\n0.1050231\n\n\nOther race, nec\n0.0376731\n\n\nThree or more major races\n0.1048730\n\n\nTwo major races\n0.0882288\n\n\nWhite\n0.1676538\n\n\n\n\n\nAnalysis to the table: - The Chinese group exhibits the highest log_INCTOT coefficient, indicating the strongest positive association between income and the variable of interest in this dataset.\n\nAmerican Indian or Alaska Native, Other Asian or Pacific Islander, Other race, nec, Three or more major races, and White categories display coefficients ranging from approximately 0.0376 to 0.1676, suggesting varied degrees of positive association between income and the variable measured.\nThe Black/African American and Two major races groups have relatively lower coefficients of approximately 0.0621 and 0.0882, respectively, implying a weaker positive relationship compared to the other groups.\nThere is no negative coefficient present, which would indicate a negative relationship between income and the variable; all listed races have positive coefficients, implying a positive relationship across the board.\n\n\n\n\n\n\n\n\nConfimed that RACE is a factor and has at least two levels.\n\n\ndata_twenty$RACE &lt;- factor(data_twenty$RACE)\nif (length(levels(data_twenty$RACE)) &lt; 2) {\n  stop(\"RACE must have at least two levels\")\n}\n\n\nNo need to drop because all has more than one level.\n\n\n# Convert categorical variables to factors\ncategorical_vars &lt;- c(\"KITCHEN\", \"MARST\", \"EMPSTAT\", \"REGION_CLASSIFIED\")\ndata_twenty[categorical_vars] &lt;- lapply(data_twenty[categorical_vars], factor)\n\n# Convert categorical variables to factors\ncategorical_vars &lt;- c(\"KITCHEN\", \"MARST\", \"EMPSTAT\", \"REGION_CLASSIFIED\")\ndata_twenty[categorical_vars] &lt;- lapply(data_twenty[categorical_vars], factor)\n\n# Check the number of levels per categorical variable within each RACE group\nrace_levels &lt;- data_twenty %&gt;%\n  group_by(RACE) %&gt;%\n  summarize(across(all_of(categorical_vars), ~n_distinct(.))) %&gt;%\n  ungroup()\n\n# Identify RACE groups with any categorical variable having only one level\nraces_with_single_levels &lt;- race_levels %&gt;%\n  filter(if_any(everything(), ~.x == 1)) %&gt;%\n  pull(RACE) # Extract the RACE values with problematic levels\n\n# Filter out the problematic RACE groups from the main dataset\ndata_twenty_filtered &lt;- data_twenty %&gt;%\n  filter(!RACE %in% races_with_single_levels)\nprint(races_with_single_levels)\n\nfactor()\n9 Levels: American Indian or Alaska Native Black/African American ... White\n\n\n\n# Convert categorical variables to factors again after subsetting just in case\ndata_twenty_filtered[categorical_vars] &lt;- lapply(data_twenty_filtered[categorical_vars], factor)\n\n# Check the number of levels per categorical variable within each RACE-YEAR group\nrace_year_levels &lt;- data_twenty_filtered %&gt;%\n  group_by(RACE, YEAR) %&gt;%\n  summarize(across(all_of(categorical_vars), ~n_distinct(.))) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'RACE'. You can override using the\n`.groups` argument.\n\n# Identify RACE-YEAR groups with any categorical variable having only one level\nrace_year_with_single_levels &lt;- race_year_levels %&gt;%\n  filter(if_any(everything(), ~.x == 1)) \n\n# Display the RACE-YEAR groups with issues, if any\nprint(race_year_with_single_levels)\n\n# A tibble: 58 × 6\n   RACE                             YEAR KITCHEN MARST EMPSTAT REGION_CLASSIFIED\n   &lt;fct&gt;                           &lt;dbl&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt;             &lt;int&gt;\n 1 American Indian or Alaska Nati…  2000       1     2       3                 4\n 2 American Indian or Alaska Nati…  2002       1     4       3                 4\n 3 American Indian or Alaska Nati…  2003       1     4       3                 4\n 4 American Indian or Alaska Nati…  2004       1     4       3                 3\n 5 American Indian or Alaska Nati…  2006       1     6       3                 4\n 6 American Indian or Alaska Nati…  2010       1     5       3                 4\n 7 American Indian or Alaska Nati…  2019       1     5       3                 4\n 8 Black/African American           2001       1     6       3                 4\n 9 Chinese                          2000       1     3       2                 3\n10 Chinese                          2002       1     4       3                 3\n# ℹ 48 more rows\n\n\n\n# Filter out the problematic RACE-YEAR groups from the main dataset\ndata_twenty_filtered_final &lt;- data_twenty_filtered %&gt;%\n  anti_join(race_year_with_single_levels, by = c(\"RACE\", \"YEAR\"))\n\n\n# Now, with the cleaned data, fit the models\nmodels_by_race_year &lt;- data_twenty_filtered_final %&gt;%\n  group_by(RACE, YEAR) %&gt;%\n  do(\n    model = lm(log_RENTGRS ~ log_INCTOT + KITCHEN + ROOMS + NFAMS + AGE + MARST + EMPSTAT + REGION_CLASSIFIED, data = .)\n  )\n\n\nmodels_with_coef &lt;- models_by_race_year %&gt;%\n  rowwise() %&gt;% \n  mutate(log_INCTOT_coef = coef(model)[[\"log_INCTOT\"]]) %&gt;%\n  ungroup() %&gt;%\n  select(RACE, YEAR, log_INCTOT_coef)\n\ncoefficients_wide &lt;- models_with_coef %&gt;%\n  pivot_wider(names_from = RACE, values_from = log_INCTOT_coef, names_prefix = \"coef_\")\n\nkable(coefficients_wide)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYEAR\ncoef_American Indian or Alaska Native\ncoef_Black/African American\ncoef_Chinese\ncoef_Japanese\ncoef_Other Asian or Pacific Islander\ncoef_Other race, nec\ncoef_Three or more major races\ncoef_Two major races\ncoef_White\n\n\n\n\n2001\n0.0044494\nNA\n0.0097707\nNA\n0.1221862\n0.0818381\nNA\n0.1007001\n0.1445229\n\n\n2005\n-0.1728914\n0.0873527\n0.1326179\nNA\n0.0897322\n0.0429701\nNA\nNA\n0.1379574\n\n\n2007\n0.1239418\n0.1115806\nNA\nNA\n0.0864570\n0.1019018\nNA\n0.0988822\n0.1401784\n\n\n2008\n0.1662273\n0.0717442\nNA\nNA\n0.0495650\n0.0811385\nNA\n0.0705536\n0.1261771\n\n\n2009\n-0.0290841\n0.0982650\n0.0462740\nNA\n0.0979882\n0.1357880\nNA\n0.0883666\n0.1215903\n\n\n2011\n-0.0246266\n0.1289264\n0.1080701\n-0.3049829\n0.1056626\n0.0704745\nNA\n0.0950769\n0.1434630\n\n\n2012\n0.0829896\n0.0815911\n0.1408589\n0.2402733\n0.0947194\n0.0336927\nNA\n0.0447647\n0.1477391\n\n\n2013\n0.1450099\n0.1208850\nNA\n0.3074672\n0.0719337\n0.0944647\nNA\n0.1077284\n0.1413223\n\n\n2014\n-0.0806190\n0.0774011\n0.1243816\n0.1948937\n0.1704745\n0.0192973\n-0.0246775\n0.0501507\n0.1423022\n\n\n2015\n0.2288886\n0.0866523\n0.1437636\nNA\n0.0588220\n0.0124419\n-0.0798592\n0.0240695\n0.1366126\n\n\n2016\n0.0724100\n0.1070357\n0.0935354\nNA\n0.0892159\n0.0831495\nNA\n0.1105840\n0.1281357\n\n\n2017\n0.1140436\n0.1154084\n0.0120262\n0.0758910\n0.0610027\n0.1443399\nNA\n0.0379656\n0.1514833\n\n\n2018\n0.1443089\n0.1216139\n0.2833792\nNA\n0.1070153\n0.0425257\n0.3835364\n0.1375949\n0.1594088\n\n\n2020\n0.0264148\n0.0821522\n0.0947932\nNA\n0.1345643\n0.1008466\nNA\n0.0531118\n0.1628788\n\n\n2021\n-0.0599569\n0.0664240\n0.1149156\nNA\n0.1242797\n0.0334209\n-0.0382770\n0.0856113\n0.1649109\n\n\n2022\n0.0984965\n0.0632937\n0.2196783\nNA\n0.1033151\n0.0390094\n0.0722550\n0.0800541\n0.1637250\n\n\n2000\nNA\n0.0358345\nNA\nNA\nNA\nNA\nNA\nNA\n0.1459856\n\n\n2002\nNA\n0.0994888\nNA\nNA\nNA\n0.1131498\nNA\nNA\n0.1290758\n\n\n2003\nNA\n0.1201889\nNA\nNA\n0.0611945\n0.0426896\nNA\n-0.0781177\n0.1278780\n\n\n2004\nNA\n0.1245230\n0.0048313\nNA\n0.0655594\nNA\nNA\n0.0013052\n0.1292762\n\n\n2006\nNA\n0.1192481\n0.0993890\n0.4505390\n0.1058852\n0.0840827\nNA\nNA\n0.1273188\n\n\n2010\nNA\n0.0965021\nNA\n-0.8670287\n0.1104422\n0.0597122\nNA\n0.0686506\n0.1432963\n\n\n2019\nNA\n0.1027066\n0.2814538\nNA\n0.1331487\n0.0892457\nNA\nNA\n0.1464698\n\n\n\n\n\n\nSpecific Trends:\n\nAlaska Native: Shows minor fluctuations around zero, with both positive and negative coefficients, indicating inconsistent trends over the years.\nAmerican: This category has NA values, suggesting incomplete data, making it hard to discern a clear trend.\nChinese: Generally has higher positive coefficients compared to other groups, particularly noticeable in later years, indicating a strong positive association with income in those years.\nJapanese: Has some missing values but otherwise presents mostly positive coefficients, with a notable spike in recent years.\nIslander: Also features both positive and negative coefficients with considerable variability.\nOther race, nec: Shows a mix of positive, negative, and NA values, making a clear trend difficult to establish.\nTwo or more races: This group generally has positive coefficients, with a few exceptions, suggesting a fairly consistent positive association with income.\nWhites: Present a range of coefficients, mostly positive with some fluctuations, but generally indicate a positive association with income.\n\nRace Comparisons: Certain racial categories, like those identifying as Chinese and Japanese, tend to have higher coefficients, suggesting a stronger relationship with income than other races in the dataset. Conversely, the ‘Other race, nec’ category often has lower coefficients, implying a weaker association with income."
  },
  {
    "objectID": "posts/2024-03-23-class-blog-2/class-blog-2.html",
    "href": "posts/2024-03-23-class-blog-2/class-blog-2.html",
    "title": "Class Blog 2",
    "section": "",
    "text": "Our research aims to utilize 2022 U.S. data to determine whether income influences Americans’ rental choices and to explore the impact of race, age, and other factors."
  },
  {
    "objectID": "posts/2024-03-23-class-blog-2/class-blog-2.html#our-topic",
    "href": "posts/2024-03-23-class-blog-2/class-blog-2.html#our-topic",
    "title": "Class Blog 2",
    "section": "",
    "text": "Our research aims to utilize 2022 U.S. data to determine whether income influences Americans’ rental choices and to explore the impact of race, age, and other factors."
  },
  {
    "objectID": "posts/2024-03-23-class-blog-2/class-blog-2.html#source",
    "href": "posts/2024-03-23-class-blog-2/class-blog-2.html#source",
    "title": "Class Blog 2",
    "section": "Source",
    "text": "Source\nThe data comes from IPUMS USA.\nThe original data of this website came from censuses as well as the American Community Surveys (ACS) that began in 2000 and are still going on today. We chose our dataset from this website because this website contains datasets that are large, valid and complex, containing detailed microdata. This site aims to facilitate transformative research, education, and policy-making by aggregating data across times and places, which makes the datasets on this website very appropriate for our research while streamlining our analysis of changes, data merging, and comparative research."
  },
  {
    "objectID": "posts/2024-03-23-class-blog-2/class-blog-2.html#other-research-on-similar-topics",
    "href": "posts/2024-03-23-class-blog-2/class-blog-2.html#other-research-on-similar-topics",
    "title": "Class Blog 2",
    "section": "Other Research on Similar Topics",
    "text": "Other Research on Similar Topics\n\nA U.S. Census Bureau reasearch: “Share of Income Needed to Pay Rent Increased the Most for Low-Income Households From 2019 to 2021”\n\nFrom Census.Gov\nResearch conducted by the U.S. Census Bureau from 2019 to 2021 indicates a widespread trend of increased rent burden among renter households across all income levels. Notably, the study shows that the lowest-income quantile experienced the most significant impact, with the number of cost-burdened renter-occupied households rising from 85.5% to 87.3%, equating to approximately 10.9 million households in 2021.\n\n\n\nA Harvard research: “More Renters Than Ever Before Are Burdened by the Rent They Pay”\n\nFrom NEW YORK TIMES\nThe Harvard report also highlights this critical issue in the housing sector, revealing a substantial increase in rental burden across the United States using 2022 census data and draws similar concern as the study of U.S. Census Bureau. It found that an unprecedented 22.4 million households now allocate over 30% of their income to rent, with 12.1 million of U.S. households spending more than half of their income on this expense. This situation underscores the growing challenge of affordable housing, affecting renters’ financial stability and quality of life.\nThese studies reveal that low-income renters face a significant rent burden, guiding the creation of targeted affordable housing initiatives, for example like rental assistance programs tailored to prevent excessive rent spending, and housing policy reforms like rent control and incentives for low-income housing development. Underpinning the vital research on rent and income relationships effectively combat the housing affordability crisis. It underscores the commitment to ensuring everyone has access to safe, affordable housing and bolsters the economic resilience of low-income families by mitigating their rent-related financial pressures."
  },
  {
    "objectID": "posts/2024-03-23-class-blog-2/class-blog-2.html#reference",
    "href": "posts/2024-03-23-class-blog-2/class-blog-2.html#reference",
    "title": "Class Blog 2",
    "section": "Reference:",
    "text": "Reference:\nKaysen, R. (2024, January 25). More renters than ever before are burdened by the rent they pay. The New York Times. https://www.nytimes.com/2024/01/25/realestate/rent-prices-housing.html\nPeter J. Mateyka and Jayne Yoo. (2023b, February 28). Share of income needed to pay rent increased the most for low-income households from 2019 to 2021. Census.gov. https://www.census.gov/library/stories/2023/03/low-income-renters-spent-larger-share-of-income-on-rent.html"
  },
  {
    "objectID": "posts/2024-03-23-class-blog-2/class-blog-2.html#data-loading-and-cleaning",
    "href": "posts/2024-03-23-class-blog-2/class-blog-2.html#data-loading-and-cleaning",
    "title": "Class Blog 2",
    "section": "Data Loading and Cleaning",
    "text": "Data Loading and Cleaning\n\nVariables we have\n\n\n\n\n\n\n\n\nVariable\nDescription\nNotes\n\n\n\n\nRENTGRS\nMonthly gross rent\n\n\n\nINCTOT\nTotal personal income\nSpecific codes detailed below:\n\n\n\n\n0000001 = $1 or break even (2000, 2005-onward ACS and PRCS)\n\n\n\n\n9999999 = N/A\n\n\n\n\n9999998 = Unknown\n\n\nFTOTINC\nTotal family income\nSpecific codes detailed below:\n\n\n\n\n-000001 = Net loss (1950)\n\n\n\n\n9999998 = Not ascertained (1950)\n\n\n\n\n9999999 = N/A\n\n\nHHINCOME\nTotal household income\n\n\n\nKITCHEN\nKitchen or cooking facilities\n0 = N/A\n\n\nROOMS\nNumber of rooms\n00 = N/A\n\n\nBEDROOMS\nNumber of bedrooms\n\n\n\nNFAMS\nNumber of families in household\n\n\n\nAGE\nAge\n\n\n\nMARST\nMarital status\n\n\n\nEMPSTAT\nEmployment status\n0=N/A\n\n\n\n\n9 = Unknown/Illegible\n\n\nPOVERTY\nPoverty status\n000 = N/A\n\n\n\nData cleanning code:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/yating/Desktop/Final Project MA415\n\nlibrary(dplyr)\ndata_path &lt;- here(\"dataset-ignore\", \"twok22_data.csv\")\nlibrary(readr)\nrent_data &lt;- read_csv(data_path,show_col_types = FALSE)\nprint(head(rent_data))\n\n# A tibble: 6 × 16\n   YEAR REGION RENTGRS KITCHEN       ROOMS NFAMS   AGE MARST RACE  RACED EMPSTAT\n  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  \n1  2022     31    1200 Yes (shared …     4     1    16 Neve… Othe…   700 Not in…\n2  2022     31     253 Yes (shared …     3     1    63 Wido… White   100 Employ…\n3  2022     42    3000 Yes (shared …     7     1    76 Marr… White   100 Employ…\n4  2022     42    2242 Yes (shared …     5     4    24 Neve… White   100 Not in…\n5  2022     41    1403 Yes (shared …     3     1    54 Marr… White   100 Employ…\n6  2022     33    1450 Yes (shared …     3     1    33 Neve… Othe…   700 Not in…\n# ℹ 5 more variables: EMPSTATD &lt;dbl&gt;, INCTOT &lt;dbl&gt;, FTOTINC &lt;dbl&gt;,\n#   POVERTY &lt;dbl&gt;, REGION_CLASSIFIED &lt;chr&gt;\n\n\n\n# Clean the data\nlibrary(tidyverse)\nlibrary(here)\ndata_path &lt;- here(\"dataset-ignore\", \"twok22_data.csv\")\nlibrary(readr)\nrent_data &lt;- read_csv(data_path,show_col_types = FALSE)\n\n\nprint(rent_data)\n\n# A tibble: 6,001 × 16\n    YEAR REGION RENTGRS KITCHEN      ROOMS NFAMS   AGE MARST RACE  RACED EMPSTAT\n   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  \n 1  2022     31    1200 Yes (shared…     4     1    16 Neve… Othe…   700 Not in…\n 2  2022     31     253 Yes (shared…     3     1    63 Wido… White   100 Employ…\n 3  2022     42    3000 Yes (shared…     7     1    76 Marr… White   100 Employ…\n 4  2022     42    2242 Yes (shared…     5     4    24 Neve… White   100 Not in…\n 5  2022     41    1403 Yes (shared…     3     1    54 Marr… White   100 Employ…\n 6  2022     33    1450 Yes (shared…     3     1    33 Neve… Othe…   700 Not in…\n 7  2022     22    2089 Yes (shared…     6     1    17 Neve… White   100 Employ…\n 8  2022     41    1103 Yes (shared…     6     1    39 Neve… Othe…   700 Employ…\n 9  2022     41     968 Yes (shared…     4     1    40 Divo… White   100 Employ…\n10  2022     42    2637 Yes (shared…     7     1    23 Marr… Two …   826 Not in…\n# ℹ 5,991 more rows\n# ℹ 5 more variables: EMPSTATD &lt;dbl&gt;, INCTOT &lt;dbl&gt;, FTOTINC &lt;dbl&gt;,\n#   POVERTY &lt;dbl&gt;, REGION_CLASSIFIED &lt;chr&gt;\n\nrent_data_clean &lt;- rent_data %&gt;%\n  filter(RENTGRS != 0,\n         !is.na(RENTGRS),\n         EMPSTAT != \"0\" & EMPSTAT != \"9\",\n         KITCHEN != \"0\", # Filter out rows where Kitchen is \"0\"\n         ROOMS != \"00\", # Filter out rows where Rooms is \"00\"\n         !INCTOT %in% c(1, 9999999, 9999998, -000001, \"FTOTINC-000001\"), # Filter based on INCTOT criteria\n         !FTOTINC %in% c(9999998, 9999999), # Filter based on FTOTINC criteria\n         POVERTY != 000\n         ) # Filter based on POVERTY criteria\nrent_data_clean$REGION_CLASSIFIED &lt;- case_when(\n  rent_data_clean$REGION %in% c(11, 12, 13) ~ \"NORTHEAST\",\n  rent_data_clean$REGION %in% c(21, 22, 23) ~ \"MIDWEST\",\n  rent_data_clean$REGION %in% c(31, 32, 33, 34) ~ \"SOUTH\",\n  rent_data_clean$REGION %in% c(41, 42, 43) ~ \"WEST\",\n  TRUE ~ \"OTHER\"\n)\n\nsaveRDS(rent_data_clean, file = here(\"dataset\", \"latest.RData\"))\nwrite_csv(rent_data_clean, file = here(\"dataset\", \"latest.csv\"))\n\nWe exclude data entries characterized by specific codes indicative of missing or unknown values, as well as those representing values deemed inappropriate for analytical purposes. Furthermore, for our dependent variable—rent—we exclude records indicating a rent of 0. This exclusion is based on the understanding that a 0 rent suggests the individual owns their home or lives in a situation not pertinent to our target research population, which is individuals who rent their housing. Given the original dataset comprises millions of samples, the exclusion of these data points still leaves us with the sufficiently cleaned large dataset for robust analysis."
  },
  {
    "objectID": "posts/2024-04-12-class-blog-5/class-blog-5.html",
    "href": "posts/2024-04-12-class-blog-5/class-blog-5.html",
    "title": "Class blog 5",
    "section": "",
    "text": "Previously, we investigate the relationship between rent spending and income. In this blog, we merged the dataset from 2000 to 2022, to get a further insight on the trend of the rent in these twenty years."
  },
  {
    "objectID": "posts/2024-04-12-class-blog-5/class-blog-5.html#visualize-the-pattern-in-22-yrs",
    "href": "posts/2024-04-12-class-blog-5/class-blog-5.html#visualize-the-pattern-in-22-yrs",
    "title": "Class blog 5",
    "section": "Visualize the pattern in 22 yrs",
    "text": "Visualize the pattern in 22 yrs\n\nRent trend\n\n\n\n\n\n\nThe chart displays the trend of median gross rent from the early 2000s to the early 2020s, give a general view of the change on gross rent in 20 years.\nMedian values are used to represent the data to mitigate the effects of large outliers on the analysis, as explored in class blog 3.\nThere is a clear and steady increase in the median gross rent over the years, indicating a consistent rise in rental costs.\nNo periods of decline or stagnation are visible, suggesting a persistent demand for housing or other market pressures driving up rent.\n\n\n\nIncome trend\n\n\n\n\n\n\nThe plot shows a rising trend in median personal income from 2000 to 2020.\nIncome levels appear to remain relatively stable in the early 2000s, with minimal fluctuation.\nAround 2010, there is a noticeable dip, which could correspond to the after-effects of the 2008 financial crisis.\nFollowing the dip, there is a strong upward trend, with income levels significantly rising, especially post-2015.\nThe steepest increase in median income occurs in the last few years of the data, suggesting a recent boost in personal income levels."
  },
  {
    "objectID": "posts/2024-04-12-class-blog-5/class-blog-5.html#group-by-year-fit-same-log-log-model-like-2022-in-class-blog-4",
    "href": "posts/2024-04-12-class-blog-5/class-blog-5.html#group-by-year-fit-same-log-log-model-like-2022-in-class-blog-4",
    "title": "Class blog 5",
    "section": "Group by YEAR, fit same log-log model like 2022 in class blog 4",
    "text": "Group by YEAR, fit same log-log model like 2022 in class blog 4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n2000\n0.3004684\n0.2734731\n0.4224935\n11.13038\n0\n23\n-333.323\n716.6461\n827.3891\n106.3864\n596\n620\n\n\n2001\n0.2470440\n0.2375703\n0.4343406\n26.07673\n0\n23\n-1071.364\n2192.7289\n2330.8294\n344.8555\n1828\n1852\n\n\n2002\n0.2331442\n0.2219811\n0.4474190\n20.88527\n0\n23\n-973.854\n1997.7081\n2132.2145\n316.2903\n1580\n1604\n\n\n2003\n0.2465441\n0.2370067\n0.4480918\n25.85020\n0\n23\n-1122.311\n2294.6224\n2432.5740\n364.8287\n1817\n1841\n\n\n2004\n0.2503521\n0.2402157\n0.4474393\n24.69849\n0\n23\n-1048.315\n2146.6299\n2282.9544\n340.5435\n1701\n1725\n\n\n2005\n0.2578132\n0.2537284\n0.4519094\n63.11557\n0\n23\n-2613.433\n5276.8654\n5435.4542\n853.4443\n4179\n4203\n\n\n2006\n0.2886511\n0.2846915\n0.4463248\n72.89924\n0\n23\n-2532.394\n5114.7885\n5273.0962\n823.1186\n4132\n4156\n\n\n2007\n0.2579863\n0.2539132\n0.4657137\n63.33896\n0\n23\n-2747.100\n5544.2009\n5702.8551\n908.7660\n4190\n4214\n\n\n2008\n0.2473125\n0.2433582\n0.4633991\n62.54309\n0\n23\n-2848.263\n5746.5269\n5906.2723\n940.1263\n4378\n4402\n\n\n2009\n0.2549819\n0.2512881\n0.4705660\n69.03019\n0\n23\n-3089.421\n6228.8423\n6390.0277\n1027.2247\n4639\n4663\n\n\n2010\n0.2679043\n0.2644022\n0.4511145\n76.49772\n0\n23\n-2997.845\n6045.6891\n6207.7645\n978.4487\n4808\n4832\n\n\n2011\n0.2603548\n0.2568985\n0.4740125\n75.32791\n0\n23\n-3313.745\n6677.4909\n6840.1493\n1105.9138\n4922\n4946\n\n\n2012\n0.2771554\n0.2739096\n0.4600769\n85.38670\n0\n23\n-3294.673\n6639.3453\n6802.9947\n1084.1776\n5122\n5146\n\n\n2013\n0.2761514\n0.2728593\n0.4602770\n83.88121\n0\n23\n-3255.114\n6560.2281\n6723.5597\n1071.3503\n5057\n5081\n\n\n2014\n0.2739684\n0.2708225\n0.4612843\n87.08596\n0\n23\n-3428.168\n6906.3364\n7070.8734\n1129.4535\n5308\n5332\n\n\n2015\n0.2676026\n0.2643909\n0.4591722\n83.32228\n0\n23\n-3363.339\n6776.6777\n6940.9176\n1105.8510\n5245\n5269\n\n\n2016\n0.2617749\n0.2585815\n0.4688414\n81.97435\n0\n23\n-3520.766\n7091.5316\n7256.1108\n1168.7418\n5317\n5341\n\n\n2017\n0.2588462\n0.2556947\n0.4728262\n82.13395\n0\n23\n-3627.601\n7305.2017\n7470.2079\n1209.2611\n5409\n5433\n\n\n2018\n0.2877600\n0.2847376\n0.4738139\n95.20847\n0\n23\n-3646.330\n7342.6610\n7507.7177\n1216.7881\n5420\n5444\n\n\n2019\n0.2898507\n0.2867566\n0.4801230\n93.68034\n0\n23\n-3621.724\n7293.4472\n7457.8479\n1216.9048\n5279\n5303\n\n\n2020\n0.2820342\n0.2778789\n0.4948471\n67.87314\n0\n23\n-2848.262\n5746.5231\n5903.8619\n973.1280\n3974\n3998\n\n\n2021\n0.2677132\n0.2643873\n0.4841706\n80.49233\n0\n23\n-3517.113\n7084.2259\n7247.5919\n1187.1087\n5064\n5088\n\n\n2022\n0.2239915\n0.2205238\n0.5099087\n64.59389\n0\n23\n-3842.513\n7735.0255\n7898.7961\n1338.2554\n5147\n5171\n\n\n\n\n\n\nThe r.squared values across the years fluctuate but generally stay within a narrow range, suggesting a consistent level of variability in the response variable that is explained by the model.\nThe adj.r.squared values are consistently slightly lower than the r.squared values, which is expected as they adjust for the number of predictors in the model relative to the number of observations. But generally, both of these indicators are in a acceptable range.\nThe p.value column shows zeros across all years, indicating that the overall model is statistically significant each year.\nThe logLik (log-likelihood) values are negative and increase in magnitude over time, possibly indicating that the model’s fit is improving or that the variability in the data is increasing.\nThe AIC and BIC values also generally increase over time, which could suggest that the complexity of the model or the information loss is growing.\nThe deviance shows how much of the total variability is not explained by the model; the trends here are not immediately clear without further context.\nhe df.residual (degrees of freedom of residuals) decreases slightly over time, indicating that there might be more parameters in the model or less data available in later years.\n\n\n\n\n\n\n\nThe coefficient for log_INCTOT has fluctuated over the years, indicating varying degrees of association between INCTOT and the dependent variable in the model.\nThere are some years where the coefficient estimate peaks sharply, particularly noticeable in the early 2000s and again around 2020.\nConversely, there are troughs that follow these peaks, suggesting periods of less influence or a negative correction in the relationship.\nThe trend is not monotonic; it does not consistently increase or decrease but rather has multiple peaks and valleys.\nThe repeated rise and fall of the coefficient estimate could imply a cyclical pattern that repeats over several years.\nThe range of the coefficient estimates is relatively tight, with the lowest around 0.12 and the highest just above 0.14.\n\n\n\n\n\n\n\nLike the previous plot for log_INCTOT coefficients, the R-squared values here also show variability over time with no clear or consistent trend.\nThe R-squared values represent the proportion of the variance for the dependent variable that’s explained by the independent variables in the model. The fluctuation suggests that the model’s explanatory power changes from year to year.\nNotably, there’s a sharp drop in the R-squared value in the most recent year shown, which could indicate a sudden decrease in the model’s predictive power or a significant change in the underlying data structure for these years."
  },
  {
    "objectID": "posts/2024-04-19-blog-post-7/blog-post-7.html",
    "href": "posts/2024-04-19-blog-post-7/blog-post-7.html",
    "title": "Blog Post 7",
    "section": "",
    "text": "123123123"
  },
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post. You’ll want to render your post to see what it will look like on the site.\n\nEvery time you want to make a new post, you can repeat step 2 above.\nWhen you want to publish your progress, follow steps 4-7 from Customize your site.\n\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (For your first blog post, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext time, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2024-03-30-class-blog-4/class-blog-4.html",
    "href": "posts/2024-03-30-class-blog-4/class-blog-4.html",
    "title": "Class blog 4",
    "section": "",
    "text": "The horizontal axis represents the total income (INCTOT), which is the predictor.\nThe vertical axis represents the rent paid (RENTGRS), which is the response.\nThe purpose of creating this scatter plot is to assess whether there is a linear or non-linear relationship between total income and rent paid in a general way.\nThere seems to be a large concentration of points towards the lower end of the income scale with lower rents, which suggests that a significant portion of the dataset includes individuals with lower income and rent levels.\nThe plot does not clearly show a distinct linear trend, suggesting that the relationship between these variables might be non-linear"
  },
  {
    "objectID": "posts/2024-03-30-class-blog-4/class-blog-4.html#roughly-see-the-relationship-between-predictor-and-response-variable",
    "href": "posts/2024-03-30-class-blog-4/class-blog-4.html#roughly-see-the-relationship-between-predictor-and-response-variable",
    "title": "Class blog 4",
    "section": "",
    "text": "The horizontal axis represents the total income (INCTOT), which is the predictor.\nThe vertical axis represents the rent paid (RENTGRS), which is the response.\nThe purpose of creating this scatter plot is to assess whether there is a linear or non-linear relationship between total income and rent paid in a general way.\nThere seems to be a large concentration of points towards the lower end of the income scale with lower rents, which suggests that a significant portion of the dataset includes individuals with lower income and rent levels.\nThe plot does not clearly show a distinct linear trend, suggesting that the relationship between these variables might be non-linear"
  },
  {
    "objectID": "posts/2024-03-30-class-blog-4/class-blog-4.html#simple-linear-model",
    "href": "posts/2024-03-30-class-blog-4/class-blog-4.html#simple-linear-model",
    "title": "Class blog 4",
    "section": "Simple linear model",
    "text": "Simple linear model\nThe output of fitting a simple linear model will get the summary like following:\n\nRegression Coefficients Table:\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1369.9952048\n14.2472905\n96.15830\n0\n\n\nINCTOT\n0.0053213\n0.0002182\n24.39103\n0\n\n\n\n\n\n\n\nModel Fit Statistics Table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.0902228\n0.0900712\n896.1935\n594.9223\n0\n1\n-49309.79\n98625.57\n98645.67\n4818173576\n5999\n6001\n\n\n\n\n\n\n\nResiduals and Related Statistics Table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRENTGRS\nINCTOT\n.fitted\n.resid\n.hat\n.sigma\n.cooksd\n.std.resid\n\n\n\n\n1200\n0\n1369.995\n-169.99520\n0.0002527\n896.2655\n0.0000045\n-0.1897098\n\n\n253\n49200\n1631.803\n-1378.80263\n0.0001739\n896.0913\n0.0002059\n-1.5386438\n\n\n3000\n89900\n1848.379\n1151.62090\n0.0003256\n896.1448\n0.0002690\n1.2852229\n\n\n2242\n1500\n1377.977\n864.02286\n0.0002461\n896.1988\n0.0001144\n0.9642217\n\n\n1403\n34000\n1550.919\n-147.91904\n0.0001676\n896.2662\n0.0000023\n-0.1650664\n\n\n1450\n2000\n1380.638\n69.36222\n0.0002439\n896.2678\n0.0000007\n0.0774059\n\n\n\n\n\n\nThe R-squared value is 0.09, which means that approximately 9% of the variability in the rent paid (RENTGRS) can be explained by the total income (INCTOT). This is a relatively low R-squared value, indicating that the linear model does not explain a large portion of the variability in the rent.But it is fair, because we only include one predictor here.\nThe statistic value is 594, which is extremely high. This suggests that the overall significance of the model is strong, despite the low R-squared. This could be due to a large sample size, which can make even small relationships appear statistically significant.\n\n\n\nResidual plot\n\n\n\n\n\n\nThis diagram indicates that the spread of residuals appears to increase as the fitted values increase. This pattern indicates heteroscedasticity, which means that the variability of the residuals is not constant across levels of the predictor variable. In an ideal scenario, I’d want to see a consistent spread of residuals across all levels of fitted values, suggesting homoscedasticity."
  },
  {
    "objectID": "posts/2024-03-30-class-blog-4/class-blog-4.html#multiple-linear-regression",
    "href": "posts/2024-03-30-class-blog-4/class-blog-4.html#multiple-linear-regression",
    "title": "Class blog 4",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nWe strive to enhance model accuracy by incorporating additional control variables into the model, encompassing both categorical and numerical variables. These control variables help mitigate bias, isolate effects, and enhance generalization. Subsequently, we present the correlation matrix, which provides valuable insights into the relationships between numerical variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nINCTOT\nROOMS\nNFAMS\nAGE\nFTOTINC\nRENTGRS\n\n\n\n\nINCTOT\n1.0000000\n-0.0284713\n-0.0358320\n0.0418338\n0.6905567\n0.3003711\n\n\nROOMS\n-0.0284713\n1.0000000\n0.1409337\n-0.0610423\n0.1050778\n0.1457684\n\n\nNFAMS\n-0.0358320\n0.1409337\n1.0000000\n-0.1266306\n-0.1053792\n0.0966248\n\n\nAGE\n0.0418338\n-0.0610423\n-0.1266306\n1.0000000\n-0.0521530\n-0.0837413\n\n\nFTOTINC\n0.6905567\n0.1050778\n-0.1053792\n-0.0521530\n1.0000000\n0.4292341\n\n\nRENTGRS\n0.3003711\n0.1457684\n0.0966248\n-0.0837413\n0.4292341\n1.0000000\n\n\n\n\n\n\nINCTOT and FTOINC have a strong positive correlation, indicating that as individual income rises, family income tends to rise in concert suggesting a possible overlap or direct relationship between these two variables in the dataset. So we need to care about the multicollineaity problem while fitting model.\nROOMS and NFAMS display minor positive correlations to RENTGRS. This might suggest that properties with more rooms may house more families and potentially lead to higher rents.\nNotably, Age has a moderate negative correlation with Number of Families, which could hint at younger populations having larger family sizes or vice versa, but this is not a strong relationship. Still, we should observe the multicollineaity problem while fitting model.\n\n\nRegression Coefficients Table:\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n138.1185777\n141.2714323\n0.9776823\n0.3282711\n\n\nINCTOT\n0.0006097\n0.0002902\n2.1007863\n0.0357015\n\n\nKITCHENYes (shared or exclusive use)\n-6.1829776\n90.8767566\n-0.0680370\n0.9457585\n\n\nROOMS\n46.4907520\n5.3702515\n8.6570903\n0.0000000\n\n\nNFAMS\n132.1944360\n13.6931462\n9.6540586\n0.0000000\n\n\nAGE\n-2.0758142\n0.7523351\n-2.7591615\n0.0058126\n\n\nMARSTMarried, spouse absent\n49.6811716\n68.5403491\n0.7248456\n0.4685751\n\n\nMARSTMarried, spouse present\n159.9536213\n35.4269714\n4.5150239\n0.0000065\n\n\nMARSTNever married/single\n105.3336893\n36.3950074\n2.8941796\n0.0038153\n\n\nMARSTSeparated\n-8.8902061\n67.6504230\n-0.1314139\n0.8954523\n\n\nMARSTWidowed\n155.3446449\n54.6823660\n2.8408545\n0.0045145\n\n\nRACEBlack/African American\n298.3828456\n95.0013295\n3.1408281\n0.0016929\n\n\nRACEChinese\n555.5828036\n124.8976462\n4.4483048\n0.0000088\n\n\nRACEJapanese\n600.4379460\n196.2637964\n3.0593413\n0.0022281\n\n\nRACEOther Asian or Pacific Islander\n457.2962479\n99.9161477\n4.5768002\n0.0000048\n\n\nRACEOther race, nec\n326.8017293\n96.1126737\n3.4001939\n0.0006778\n\n\nRACEThree or more major races\n423.9569703\n136.5156638\n3.1055555\n0.0019081\n\n\nRACETwo major races\n344.3391572\n95.2001877\n3.6170008\n0.0003005\n\n\nRACEWhite\n374.0737917\n91.7421010\n4.0774496\n0.0000461\n\n\nEMPSTATNot in labour force\n-16.9682582\n25.5211603\n-0.6648702\n0.5061592\n\n\nEMPSTATUnemployed\n64.2293142\n54.6215828\n1.1758962\n0.2396832\n\n\nFTOTINC\n0.0042445\n0.0001887\n22.4923166\n0.0000000\n\n\nREGION_CLASSIFIEDNORTHEAST\n388.6103788\n35.8876194\n10.8285360\n0.0000000\n\n\nREGION_CLASSIFIEDSOUTH\n252.4183530\n31.3606818\n8.0488796\n0.0000000\n\n\nREGION_CLASSIFIEDWEST\n676.2307407\n33.2843111\n20.3168015\n0.0000000\n\n\n\n\n\n\n\nModel Fit Statistics Table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.2836063\n0.2807292\n796.7908\n98.57423\n0\n24\n-48592.76\n97237.51\n97411.71\n3794016209\n5976\n6001\n\n\n\n\n\n\n\nResiduals and Related Statistics Table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRENTGRS\nINCTOT\nKITCHEN\nROOMS\nNFAMS\nAGE\nMARST\nRACE\nEMPSTAT\nFTOTINC\nREGION_CLASSIFIED\n.fitted\n.resid\n.hat\n.sigma\n.cooksd\n.std.resid\n\n\n\n\n1200\n0\nYes (shared or exclusive use)\n4\n1\n16\nNever married/single\nOther race, nec\nNot in labour force\n37800\nSOUTH\n1244.907\n-44.90653\n0.0031953\n796.8572\n0.0000004\n-0.0564495\n\n\n253\n49200\nYes (shared or exclusive use)\n3\n1\n63\nWidowed\nWhite\nEmployed\n49200\nSOUTH\n1293.490\n-1040.49010\n0.0041196\n796.7433\n0.0002833\n-1.3085492\n\n\n3000\n89900\nYes (shared or exclusive use)\n7\n1\n76\nMarried, spouse present\nWhite\nEmployed\n98700\nWEST\n2115.807\n884.19328\n0.0024677\n796.7751\n0.0001222\n1.1110649\n\n\n2242\n1500\nYes (shared or exclusive use)\n5\n4\n24\nNever married/single\nWhite\nNot in labour force\n1500\nWEST\n1989.299\n252.70115\n0.0034850\n796.8507\n0.0000141\n0.3177028\n\n\n1403\n34000\nYes (shared or exclusive use)\n3\n1\n54\nMarried, spouse present\nWhite\nEmployed\n79000\nWEST\n1857.811\n-454.81093\n0.0016027\n796.8357\n0.0000210\n-0.5712614\n\n\n1450\n2000\nYes (shared or exclusive use)\n3\n1\n33\nNever married/single\nOther race, nec\nNot in labour force\n2000\nSOUTH\n1012.394\n437.60563\n0.0029432\n796.8373\n0.0000357\n0.5500202\n\n\n\n\n\n\nThe R-squared value is 0.28, indicating that about 28% of the variability in the dependent variable is explained by the model. This is a significant improvement over the simple linear model previously discussed, suggesting that including more variables helps explain the variance in the dependent variable more effectively.\nThe adjusted R-squared value is 0.2807292, which is very close to the R-squared value.Since the adjusted R-squared is almost identical to the R-squared, this implies that the additional predictors are indeed contributing valuable information.\nThe statistic value is 98.57, which is very high and the p-value is 0, indicating that the model is statistically significant. It means that the likelihood of the regression results being due to chance is extremely low. ### Multicollinearity concerns\n\n\n\n\n\n\n\nGVIF\nDf\nGVIF^(1/(2*Df))\n\n\n\n\nINCTOT\n2.239087\n1\n1.496358\n\n\nKITCHEN\n1.026782\n1\n1.013303\n\n\nROOMS\n1.099700\n1\n1.048666\n\n\nNFAMS\n1.103313\n1\n1.050387\n\n\nAGE\n1.849885\n1\n1.360105\n\n\nMARST\n1.876545\n5\n1.064966\n\n\nRACE\n1.198654\n8\n1.011389\n\n\nEMPSTAT\n1.350056\n2\n1.077923\n\n\nFTOTINC\n2.181999\n1\n1.477159\n\n\nREGION_CLASSIFIED\n1.129306\n3\n1.020474\n\n\n\n\n\n\nThrough the result, INCTOT (Total Income) and FTOTINC (Family Total Income) stand out as having higher multicollinearity indicators than the others. While considering the what constitutes the Family total income, it is fair multicollinearity happens. So we decide to exclude the FTOTINC in our model. With a GVIF^(1/(2*Df)) value of INCTOT approximately 1.50 and FTOTINC is about 1.47, a VIF between 1 and 5 suggests moderate indication of multicollinearity.\nTherefore, we decide to exclude the FTOTINC to avioud the multicollineariity problem.\n\n\n\nResidual plot:\n\n\n\n\n\n\nHeterskedasticity still exits as the spread of the residuals appears to be increasing with the fitted values. According to the diagram, the residuals seem to form a pattern (rather than being randomly dispersed), it indicates that the relationship between the predictors and the response variable is not entirely linear."
  },
  {
    "objectID": "posts/2024-03-30-class-blog-4/class-blog-4.html#log---log-model",
    "href": "posts/2024-03-30-class-blog-4/class-blog-4.html#log---log-model",
    "title": "Class blog 4",
    "section": "Log - log Model",
    "text": "Log - log Model\nTaking account into the possible non-linear relationship and the right-skwed distributions of our predictor and response variable, we take log to both of them.\n\nRENTGRS:distribution of log(RENTGRS)\n\n\n\n\n\n\n\nINCTOT: distribution of log(INCTOT)"
  },
  {
    "objectID": "posts/2024-03-30-class-blog-4/class-blog-4.html#log-log-model",
    "href": "posts/2024-03-30-class-blog-4/class-blog-4.html#log-log-model",
    "title": "Class blog 4",
    "section": "Log-log model",
    "text": "Log-log model\nBased on the previous MLR model, 1. we have applied a logarithmic transformation to both the rent and income variables to mitigate skewness in their distributions. But the problem is the logarithmic transformation necessitates all data points to be positive. Consequently, this has led to the exclusion of certain data samples that contained negative values.\n\nprevious models indicated the presence of numerous outliers within our dataset. To address this, we have refined our dataset to include only those records where rent and income fall within three standard deviations from their respective sample means to minimize the impact of extreme values on the model’s performance.\n\n\nRegression Coefficients Table\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n5.1366895\n0.1226201\n41.8910906\n0.0000000\n\n\nlog_INCTOT\n0.1334432\n0.0076107\n17.5337350\n0.0000000\n\n\nKITCHENYes (shared or exclusive use)\n-0.0066589\n0.0604818\n-0.1100975\n0.9123363\n\n\nROOMS\n0.0418089\n0.0036091\n11.5843972\n0.0000000\n\n\nNFAMS\n0.0328959\n0.0101097\n3.2538811\n0.0011458\n\n\nAGE\n-0.0035812\n0.0005551\n-6.4518343\n0.0000000\n\n\nMARSTMarried, spouse absent\n0.1202898\n0.0464015\n2.5923658\n0.0095588\n\n\nMARSTMarried, spouse present\n0.2037844\n0.0234430\n8.6927664\n0.0000000\n\n\nMARSTNever married/single\n0.1093652\n0.0241080\n4.5364680\n0.0000059\n\n\nMARSTSeparated\n0.0317790\n0.0447758\n0.7097359\n0.4779001\n\n\nMARSTWidowed\n0.1002446\n0.0360708\n2.7791094\n0.0054706\n\n\nRACEBlack/African American\n0.2424495\n0.0680585\n3.5623687\n0.0003709\n\n\nRACEChinese\n0.2866273\n0.0892431\n3.2117595\n0.0013274\n\n\nRACEJapanese\n0.3098268\n0.1428295\n2.1692071\n0.0301126\n\n\nRACEOther Asian or Pacific Islander\n0.3673041\n0.0716804\n5.1241908\n0.0000003\n\n\nRACEOther race, nec\n0.2807264\n0.0690309\n4.0666797\n0.0000484\n\n\nRACEThree or more major races\n0.3545589\n0.0965627\n3.6717982\n0.0002433\n\n\nRACETwo major races\n0.2827201\n0.0683850\n4.1342400\n0.0000362\n\n\nRACEWhite\n0.2663981\n0.0659347\n4.0403296\n0.0000542\n\n\nEMPSTATNot in labour force\n-0.0362414\n0.0222232\n-1.6307879\n0.1029963\n\n\nEMPSTATUnemployed\n0.0755285\n0.0431087\n1.7520454\n0.0798256\n\n\nREGION_CLASSIFIEDNORTHEAST\n0.2785538\n0.0244365\n11.3990853\n0.0000000\n\n\nREGION_CLASSIFIEDSOUTH\n0.1917026\n0.0213271\n8.9886669\n0.0000000\n\n\nREGION_CLASSIFIEDWEST\n0.4656973\n0.0227072\n20.5088390\n0.0000000\n\n\n\n\n\n\nThe coefficient (elasticity) of 0.1334 means that a 10% increase in total income (INCTOT) is associated with an average 1.334% increase in rent gross (RENTGRS), given that other variables in the model are held constant.\nThe idea in the above conclusion that higher income leads to increased rent payments is plausible. As people earn more, they may choose to live in better accommodations or neighborhoods, which could result in higher rent expenses. And it is reliable that they only spend part of income increase on the rent.\n\n\n\nModel Fit Statistics Table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr.squared\nadj.r.squared\nsigma\nstatistic\np.value\ndf\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n0.2267794\n0.2233215\n0.5072586\n65.58265\n0\n23\n-3812.607\n7675.215\n7838.966\n1323.352\n5143\n5167\n\n\n\n\n\n\n\nResiduals and Related Statistics Table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlog_RENTGRS\nlog_INCTOT\nKITCHEN\nROOMS\nNFAMS\nAGE\nMARST\nRACE\nEMPSTAT\nREGION_CLASSIFIED\n.fitted\n.resid\n.hat\n.sigma\n.cooksd\n.std.resid\n\n\n\n\n5.533390\n10.803649\nYes (shared or exclusive use)\n3\n1\n63\nWidowed\nWhite\nEmployed\nSOUTH\n7.062756\n-1.5293665\n0.0046387\n0.5068573\n0.0017733\n-3.0219812\n\n\n8.006368\n11.406453\nYes (shared or exclusive use)\n7\n1\n76\nMarried, spouse present\nWhite\nEmployed\nWEST\n7.641411\n0.3649568\n0.0028847\n0.5072824\n0.0000626\n0.7205089\n\n\n7.715124\n7.313220\nYes (shared or exclusive use)\n5\n4\n24\nNever married/single\nWhite\nNot in labour force\nWEST\n7.165828\n0.5492953\n0.0057725\n0.5072498\n0.0002853\n1.0860093\n\n\n7.246368\n10.434116\nYes (shared or exclusive use)\n3\n1\n54\nMarried, spouse present\nWhite\nEmployed\nWEST\n7.423210\n-0.1768415\n0.0018387\n0.5073020\n0.0000093\n-0.3489430\n\n\n7.279319\n7.600903\nYes (shared or exclusive use)\n3\n1\n33\nNever married/single\nOther race, nec\nNot in labour force\nSOUTH\n6.730015\n0.5493040\n0.0045412\n0.5072499\n0.0002239\n1.0853546\n\n\n7.644441\n9.239899\nYes (shared or exclusive use)\n6\n1\n17\nNever married/single\nWhite\nEmployed\nMIDWEST\n6.961664\n0.6827765\n0.0021260\n0.5072184\n0.0001612\n1.3474457\n\n\n\n\n\n\nThe adjusted R-squared is 0.223. This value looks modest. In practical terms, it suggests that the model doesn’t explain a large portion of the variance in the logarithm of rent. But in this social science and economic contexts, however, it is not uncommon to have lower R-squared values due to the complexity of human behavior and multiple unobserved factors. So we believe it is acceptable.\nThe p-value for the overall model is extremely low, which is good. It indicates that the model predictors, as a set, are statistically significantly associated with the response variable, the logarithm of rent.\nThe sigma value is the standard deviation of the error terms and is lower. This suggests that the residuals in this model are less spread out, indicating a tighter fit of the model to the data. However, since the scale is different from the previous model (which was on a log scale), this improvement is difficult to directly compare.\n\n\n\nResidual plot\n\n\n\n\n\n\nThe residuals appear to be centered around zero, which is good as it suggests no bias in the predictions.\nThere is some evidence of heteroscedasticity as the residuals seem to fan out as the fitted values increase, which is common in non-transformed data.\nThere are no clear patterns in the residuals, which suggests that the model catch the nonlinear relationships.\nThis log-transformed model seems to perform better in terms of having residuals more consistently distributed around zero. This suggests that the log transformation helped to stabilize the variance of the residuals and improve the model’s homoscedasticity."
  },
  {
    "objectID": "posts/2024-03-26-class-blog3/class-blog3.html",
    "href": "posts/2024-03-26-class-blog3/class-blog3.html",
    "title": "Class blog3",
    "section": "",
    "text": "Incorporating the principles of data equity into our research on income and rent using IPUMS data enhances the study’s integrity and societal impact. The application of these principles ensures that our analysis is not only methodologically sound but also ethically conscious, especially in the context of housing affordability and equity.\nHow we present our data could influence: Racial equity (data involves race) Poverty equity (data involves poverty definition)\n\n\nOur research openly discusses the dataset’s scope, including its geographic coverage and time period, provided by the IPUMS. We detail how the data were collected, acknowledging the reliance on census and ACS, which might include self-reported income or housing expenses. This acknowledgment is crucial as it allows us to identify potential biases or inaccuracies inherent in the data. For example, certain groups may be underrepresented due to the methodology of data collection, or there might be inaccuracies in self-reported income or expenses that could affect the analysis of income and rent relationships.Furthermore, by being transparent about the dataset’s limitations, we aim to preemptively address any questions regarding the reliability and applicability of our findings.\n\n\n\nOur research utilizes the IPUMS data and aim to figure out disparities in housing affordability, particularly among marginalized communities. Through our analysis, we aim to identify areas, race groups where rent-to-income ratios are disproportionately different, where housing conditions may be inadequate, or where residents face significant utility burdens. Our intention is not merely to document disparities but to inform policy and intervention strategies that could alleviate such inequities. This means conducting our analysis with a clear purpose: to contribute to the discourse on housing equity and affordability in a way that is constructive and aimed at bringing about positive change. This approach aligns with the ethical obligation to use data in ways that can positively impact communities, especially those that are most vulnerable.\nWhat aspect our data and analysis could possibly influence: Possible social context for housing data Possible policy context for housing data Policy decisions on the housing market Financial decisions among different housing owner/buyers Public perception of proverty"
  },
  {
    "objectID": "posts/2024-03-26-class-blog3/class-blog3.html#data-equity",
    "href": "posts/2024-03-26-class-blog3/class-blog3.html#data-equity",
    "title": "Class blog3",
    "section": "",
    "text": "Incorporating the principles of data equity into our research on income and rent using IPUMS data enhances the study’s integrity and societal impact. The application of these principles ensures that our analysis is not only methodologically sound but also ethically conscious, especially in the context of housing affordability and equity.\nHow we present our data could influence: Racial equity (data involves race) Poverty equity (data involves poverty definition)\n\n\nOur research openly discusses the dataset’s scope, including its geographic coverage and time period, provided by the IPUMS. We detail how the data were collected, acknowledging the reliance on census and ACS, which might include self-reported income or housing expenses. This acknowledgment is crucial as it allows us to identify potential biases or inaccuracies inherent in the data. For example, certain groups may be underrepresented due to the methodology of data collection, or there might be inaccuracies in self-reported income or expenses that could affect the analysis of income and rent relationships.Furthermore, by being transparent about the dataset’s limitations, we aim to preemptively address any questions regarding the reliability and applicability of our findings.\n\n\n\nOur research utilizes the IPUMS data and aim to figure out disparities in housing affordability, particularly among marginalized communities. Through our analysis, we aim to identify areas, race groups where rent-to-income ratios are disproportionately different, where housing conditions may be inadequate, or where residents face significant utility burdens. Our intention is not merely to document disparities but to inform policy and intervention strategies that could alleviate such inequities. This means conducting our analysis with a clear purpose: to contribute to the discourse on housing equity and affordability in a way that is constructive and aimed at bringing about positive change. This approach aligns with the ethical obligation to use data in ways that can positively impact communities, especially those that are most vulnerable.\nWhat aspect our data and analysis could possibly influence: Possible social context for housing data Possible policy context for housing data Policy decisions on the housing market Financial decisions among different housing owner/buyers Public perception of proverty"
  },
  {
    "objectID": "posts/2024-03-26-class-blog3/class-blog3.html#problems-and-challenges",
    "href": "posts/2024-03-26-class-blog3/class-blog3.html#problems-and-challenges",
    "title": "Class blog3",
    "section": "Problems and Challenges",
    "text": "Problems and Challenges\n\nWe ran into a problem that the data wasn’t available for every year. So, we decided to focus on the data from 2022 since that was complete and the most up-to-date for our needs. For comparing how things have changed or stayed the same, we used data from the other years after we draw the conclusion based on 2022 dataset and do the comparsion based on it. This way, we could still make some good guesses about trends over time, using the best information we had.\nCode Conversion: Our dataset contains variables with specific codes that represent distinct groups or sets of individuals. For clarity in our analysis, it is essential to accurately interpret these codes.\n\nThe table below summarizes all variables that possess this characteristic:\n\n\n\n\n\n\n\n\nVariable\nDescription\nNotes\n\n\n\n\nINCTOT\nTotal personal income\nSpecific codes detailed below:\n\n\n\n\n-009995 = -$9,900 (1980)\n\n\n\n\n-000001 = Net loss (1950)\n\n\n\n\nFTOTINC-000001 = Net loss (1950)\n\n\nKITCHEN\nKitchen facilities\n0 = N/A\n\n\n\n\n1 = No\n\n\n\n\n2 = No, or shared use\n\n\n\n\n3 = Yes, shared use\n\n\n\n\n4 = Yes (shared or exclusive use)\n\n\n\n\n5 = Yes, exclusive use\n\n\nMARST\nMarital status\n1 = Married, spouse present\n\n\n\n\n2 = Married, spouse absent\n\n\n\n\n3 = Separated\n\n\n\n\n4 = Divorced\n\n\n\n\n5 = Widowed\n\n\n\n\n6 = Never married/single\n\n\n\n\n9 = Blank, missing\n\n\nRACE\nRace\n1 = White\n\n\n\n\n2 = Black/African American\n\n\n\n\n3 = American Indian or Alaska Native\n\n\n\n\n4 = Chinese\n\n\n\n\n5 = Japanese\n\n\n\n\n6 = Other Asian or Pacific Islander\n\n\n\n\n7 = Other race, nec\n\n\n\n\n8 = Two major races\n\n\n\n\n9 = Three or more major races\n\n\nPOVERTY\nPoverty levels\n001 = 1 percent or less of poverty threshold (including 0 or negative income)\n\n\n\n\n501 = 501 percent or more of poverty threshold\n\n\nEMPSTAT\nEmployment status\n1 = Employed\n\n\n\n\n2 = Unemployed\n\n\n\n\n3 = Not in labor force"
  },
  {
    "objectID": "posts/2024-03-26-class-blog3/class-blog3.html#data-processing",
    "href": "posts/2024-03-26-class-blog3/class-blog3.html#data-processing",
    "title": "Class blog3",
    "section": "Data processing",
    "text": "Data processing\n\n# Load the cleaned data in class_blog 2\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(forcats)\nlibrary(here)\n\nhere() starts at /Users/yating/Desktop/Final Project MA415\n\ndata_path &lt;- here(\"dataset\", \"latest.csv\")\nlibrary(readr)\nrent_data_clean &lt;- read_csv(data_path,show_col_types = FALSE)\n\n\n#KITCHEN\nrent_data_clean &lt;- rent_data_clean %&gt;%\n  mutate(KITCHEN = case_when(\n    KITCHEN == \"0\" ~ \"N/A\",\n    KITCHEN == \"1\" ~ \"No\",\n    KITCHEN == \"2\" ~ \"No, or shared use\",\n    KITCHEN == \"3\" ~ \"Yes, shared use\",\n    KITCHEN == \"4\" ~ \"Yes (shared or exclusive use)\",\n    KITCHEN == \"5\" ~ \"Yes, exclusive use\",\n    TRUE ~ as.character(KITCHEN)\n  ))\nrent_data_clean$KITCHEN &lt;- as.factor(rent_data_clean$KITCHEN)\n\n\n#MARST\nrent_data_clean &lt;- rent_data_clean %&gt;%\n  mutate(MARST = case_when(\n    MARST == \"1\" ~ \"Married, spouse present\",\n    MARST == \"2\" ~ \"Married, spouse absent\",\n    MARST == \"3\" ~ \"Separated\",\n    MARST == \"4\" ~ \"Divorced\",\n    MARST == \"5\" ~ \"Widowed\",\n    MARST == \"6\" ~ \"Never married/single\",\n    MARST == \"9\" ~ \"Blank, missing\",\n    TRUE ~ as.character(MARST)\n  ))\nrent_data_clean$MARST &lt;- as.factor(rent_data_clean$MARST)\n\n\n#RACE\nrent_data_clean &lt;- rent_data_clean %&gt;%\n  mutate(RACE = case_when(\n    RACE == \"1\" ~ \"White\",\n    RACE == \"2\" ~ \"Black/African American\",\n    RACE == \"3\" ~ \"American Indian or Alaska Native\",\n    RACE == \"4\" ~ \"Chinese\",\n    RACE == \"5\" ~ \"Japanese\",\n    RACE == \"6\" ~ \"Other Asian or Pacific Islander\",\n    RACE == \"7\" ~ \"Other race, nec\",\n    RACE == \"8\" ~ \"Two major races\",\n    RACE == \"9\" ~ \"Three or more major races\",\n    TRUE ~ as.character(RACE) \n  ))\nrent_data_clean$RACE &lt;- as.factor(rent_data_clean$RACE)\n\n\n#EMPSTAT\nrent_data_clean &lt;- rent_data_clean %&gt;%\n  mutate(EMPSTAT = case_when(\n    EMPSTAT == \"1\" ~ \"Employed\",\n    EMPSTAT == \"2\" ~ \"Unemployed\",\n    EMPSTAT == \"3\" ~ \"Not in labour force\",\n    TRUE ~ as.character(EMPSTAT) # This line should return the existing value of EMPSTAT\n  ))\n\nrent_data_clean$EMPSTAT &lt;- as.factor(rent_data_clean$EMPSTAT)"
  },
  {
    "objectID": "posts/2024-03-26-class-blog3/class-blog3.html#summary-of-numerical-variables-we-have-right-now",
    "href": "posts/2024-03-26-class-blog3/class-blog3.html#summary-of-numerical-variables-we-have-right-now",
    "title": "Class blog3",
    "section": "Summary of numerical variables we have right now",
    "text": "Summary of numerical variables we have right now\n\nlibrary(dplyr)\nlibrary(tidyr)\nsummary_data &lt;- rent_data_clean %&gt;%\n  summarise(across(c(RENTGRS, ROOMS, AGE, FTOTINC, POVERTY,INCTOT,NFAMS),\n                   list(Mean = ~mean(.x),\n                        Median = ~median(.x),\n                        Min = ~min(.x),\n                        Max = ~max(.x)),\n                   .names = \"{.col}_{.fn}\")) %&gt;%\n  pivot_longer(cols = everything(),\n               names_to = \"summary\",\n               values_to = \"value\") %&gt;%\n  separate(summary, into = c(\"variable\", \"statistic\"), sep = \"_\") %&gt;%\n  pivot_wider(names_from = \"statistic\", values_from = \"value\") %&gt;%\n  select(variable, Mean, Median, Min, Max)\nprint(summary_data)\n\n# A tibble: 7 × 5\n  variable     Mean Median   Min     Max\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 RENTGRS   1577.     1390     4   10700\n2 ROOMS        4.68      4     1      20\n3 AGE         42.6      38    16      97\n4 FTOTINC  71601.    52000 -9300 1966000\n5 POVERTY    269.      249     1     501\n6 INCTOT   38071.    25000 -9380 1423200\n7 NFAMS        1.21      1     1      20"
  },
  {
    "objectID": "posts/2024-03-26-class-blog3/class-blog3.html#plots-about-the-variables",
    "href": "posts/2024-03-26-class-blog3/class-blog3.html#plots-about-the-variables",
    "title": "Class blog3",
    "section": "Plots about the variables",
    "text": "Plots about the variables\n\nRENTGRS\n\n\nlibrary(ggplot2) \n# Histogram to show distribution of monthly gross rent\nggplot(rent_data_clean, aes(x = RENTGRS)) +\n  geom_histogram(binwidth = 100, fill = \"blue\", color = \"black\") +\n  labs(title = \"Distribution of Monthly Gross Rent\",\n       x = \"Monthly Gross Rent ($)\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\nThe histogram appears to be right-skewed, with a mode somewhere before $3000. It suggests that the mean is likely to be higher than the median, which corresponds to the stats in the above section. There are a few bars past the $6000 mark, which could be considered outliers. There’s a wide range of rents; however, the majority of the data points fall below $3000, suggesting that while there are rents across a wide range.\n2.INCTOT\n\nggplot(rent_data_clean, aes(x = INCTOT)) +\n  geom_histogram(bins = 100, fill = \"blue\", color = \"black\") +\n  theme_minimal() +\n  labs(title = \"Histogram of Total Personal Income\",\n       x = \"Total Personal Income\",\n       y = \"Frequency\")\n\n\n\n\nThe histogram shows a very high peak at the lower end of the income range, suggest a right-skewed distribution. This suggests that a significant portion of the population earns within this lower income bracket. But it is what I expected because it’s the most common income range in the datasets and our dataset is from census.\n3.FTOTINC\n\nggplot(rent_data_clean, aes(x = FTOTINC)) +\n  geom_histogram(bins = 100, fill = \"blue\", color = \"black\") +\n  theme_minimal() +\n  labs(title = \"Histogram of Total Family Income\",\n       x = \"Total Family Income\",\n       y = \"Frequency\")\n\n\n\n\nSimliarly as the INCTOT, the histogram shows that the distribution of total family income is right-skewed, meaning most families have an income toward the lower end of the scale, with fewer families earning higher incomes. The tail might include outliers, which are families with significantly higher incomes than the typical family and the variance and standard deviation are likely to be large.\n4.NFAMS\n\nnfams_counts &lt;- rent_data_clean %&gt;%\n  group_by(NFAMS) %&gt;%\n  summarise(Count = n())\n\nggplot(nfams_counts, aes(x = factor(NFAMS), y = Count, fill = factor(NFAMS))) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Bar Chart of Number of Family Members\",\n       x = \"Number of Family Members\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\nThe bar representing one family member is significantly taller than the others, indicating that single-person families are most common in this dataset. There is a rapid decrease in frequency as the number of family members increases. The families with a very large number of members are quite rare. This is what I expected and aligns with my understanding to common demographic trends.\n5.Age\n\nggplot(rent_data_clean, aes(x = AGE)) +\n  geom_histogram(bins = 30, fill = \"cornflowerblue\", color = \"black\") + \n  theme_minimal() +\n  labs(title = \"Histogram of Age\",\n       x = \"Age\",\n       y = \"Frequency\")\n\n\n\n\n6.POVERTY\n\np &lt;- ggplot(rent_data_clean, aes(x = POVERTY)) +\n  geom_histogram(binwidth = 5, fill = \"darkgreen\", color = \"black\") + \n  theme_minimal() +\n  labs(title = \"Histogram of Poverty Scores\",\n       x = \"Poverty Score\",\n       y = \"Frequency\")\n\np &lt;- p + \n  geom_vline(xintercept = 1, color = \"blue\", linetype = \"dashed\", linewidth = 1) +\n  annotate(\"text\", x = 1, y = Inf, label = \"001 = ≤1% of poverty threshold\", angle = 90, hjust = 1, vjust = 2, color = \"blue\") +\n  geom_vline(xintercept = 501, color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  annotate(\"text\", x = 501, y = Inf, label = \"501 = ≥501% of poverty threshold\", angle = 90, hjust = 1, vjust = 2, color = \"red\")\n\nprint(p)\n\n\n\n\nThis variable has both upper and lower bounds. Therefore, the histogram is characterized by notable concentrations, indicating significant proportions of individuals or families at both ends of the poverty spectrum.\n7.EMPSTAT\n\nempstat_counts &lt;- rent_data_clean %&gt;%\n  count(EMPSTAT) %&gt;%\n  mutate(Percentage = n / sum(n) * 100)\nggplot(empstat_counts, aes(x = \"\", y = n, fill = EMPSTAT)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(theta = \"y\") + \n  theme_void() + \n  geom_text(aes(label = sprintf(\"%1.1f%%\", Percentage)), position = position_stack(vjust = 0.5)) +\n  labs(title = \"Pie Chart of Employment Status\", fill = \"Employment Status\")\n\n\n\n\n\nKitchen\n\n\nkitchen_counts &lt;- rent_data_clean %&gt;%\n  group_by(KITCHEN) %&gt;%\n  summarise(Count = n()) %&gt;%\n  mutate(Percentage = Count / sum(Count) * 100)\nggplot(kitchen_counts, aes(x = \"\", y = Count, fill = factor(KITCHEN))) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(theta = \"y\") +\n  theme_void() +\n  geom_text(aes(label = sprintf(\"%1.1f%%\", Percentage)), position = position_stack(vjust = 0.5)) +\n  labs(title = \"Pie Chart of Kitchen\",fill = \"Number of Kitchens\")\n\n\n\n\n\nROOMS\n\n\nrooms_counts &lt;- rent_data_clean %&gt;%\n  group_by(ROOMS) %&gt;%\n  summarise(Count = n()) %&gt;%\n  mutate(Percentage = Count / sum(Count) * 100)\n\nggplot(rooms_counts, aes(x = factor(ROOMS), y = Count, fill = factor(ROOMS))) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = sprintf(\"%1.1f%%\", Percentage), y = Count), vjust = -0.3, color = \"black\") +\n  labs(title = \"Bar Chart of Room Counts\", x = \"Number of Rooms\", y = \"Count\") +\n  scale_fill_discrete(name = \"Number of Rooms\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\nRACE\n\n\nrace_counts &lt;- rent_data_clean %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(Count = n()) %&gt;%\n  mutate(Percentage = Count / sum(Count) * 100)\n\nggplot(race_counts, aes(x = factor(RACE), y = Count, fill = factor(RACE))) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = sprintf(\"%1.1f%%\", Percentage), y = Count), vjust = -0.3, color = \"black\") +\n  labs(title = \"Bar Chart of RACE\", x = \"RACE\", y = \"Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.5))\n\n\n\n\n11.MARST\n\nmarst_counts &lt;- rent_data_clean %&gt;%\n  group_by(MARST) %&gt;%\n  summarise(Count = n()) %&gt;%\n  mutate(Percentage = Count / sum(Count) * 100)\n\nggplot(marst_counts, aes(x = factor(MARST), y = Count, fill = factor(MARST))) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = sprintf(\"%1.1f%%\", Percentage), y = Count), vjust = -0.3, color = \"black\") +\n  labs(title = \"Bar Chart of Marital Status\", x = \"Marital Status\", y = \"Count\", fill = \"Marital Status Categories\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html",
    "href": "posts/2023-12-20-examples/examples.html",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "href": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2024-03-03-class-blog-1/class-blog-1.html",
    "href": "posts/2024-03-03-class-blog-1/class-blog-1.html",
    "title": "Class Blog 1",
    "section": "",
    "text": "The primary objective is to explore the relationship between rent and personal total income. And other questions can also be answered like: Are there significant differences in rent burdens across different race groups or geographical locations? How do factors like age, employment status, and family size influence this relationship?\n\n\n\nThe dataset under investigation is sourced from IPUMS USA, a reputable platform that aggregates data collected through the U.S. Census and American Community Surveys (ACS). Our dataset is particularly focused on the year 2022. This website also includes data from other years, facilitating for further time-series analysis if needed. The dataset is substantial, containing 1,000,000 rows and 26 columns. The data can be grouped by various categories for detailed analysis and identifying trends. This dataset contains both numerical and categorical variables. Numerical variables include age, poverty level, total personal income, number of family members in households, and family income, among others. Categorical variables encompass sex, marital status, employment status, elevator and flush toilet availability, race, etc. One of the main challenges anticipated with this dataset is the presence of missing values, which could complicate data cleaning processes and affect the data size and quality. However, given the dataset’s large size, it remains feasible to extract a substantial sample (over 10,000 records) for robust analysis.\n\n\n\nIPUMS USA website\nA PDF containing screenshots of the selected variables on the IPUMS HEALTH SURVEY website\n*Through these variables names, look for the corresponding variable name in the first link and you see the specific description of each variable. But IPUMS cannot distribute users’ selected datasets’ information directly to others."
  },
  {
    "objectID": "posts/2024-03-03-class-blog-1/class-blog-1.html#key-questions-we-want-to-explore",
    "href": "posts/2024-03-03-class-blog-1/class-blog-1.html#key-questions-we-want-to-explore",
    "title": "Class Blog 1",
    "section": "",
    "text": "The primary objective is to explore the relationship between rent and personal total income. And other questions can also be answered like: Are there significant differences in rent burdens across different race groups or geographical locations? How do factors like age, employment status, and family size influence this relationship?"
  },
  {
    "objectID": "posts/2024-03-03-class-blog-1/class-blog-1.html#introduction",
    "href": "posts/2024-03-03-class-blog-1/class-blog-1.html#introduction",
    "title": "Class Blog 1",
    "section": "",
    "text": "The dataset under investigation is sourced from IPUMS USA, a reputable platform that aggregates data collected through the U.S. Census and American Community Surveys (ACS). Our dataset is particularly focused on the year 2022. This website also includes data from other years, facilitating for further time-series analysis if needed. The dataset is substantial, containing 1,000,000 rows and 26 columns. The data can be grouped by various categories for detailed analysis and identifying trends. This dataset contains both numerical and categorical variables. Numerical variables include age, poverty level, total personal income, number of family members in households, and family income, among others. Categorical variables encompass sex, marital status, employment status, elevator and flush toilet availability, race, etc. One of the main challenges anticipated with this dataset is the presence of missing values, which could complicate data cleaning processes and affect the data size and quality. However, given the dataset’s large size, it remains feasible to extract a substantial sample (over 10,000 records) for robust analysis."
  },
  {
    "objectID": "posts/2024-03-03-class-blog-1/class-blog-1.html#link",
    "href": "posts/2024-03-03-class-blog-1/class-blog-1.html#link",
    "title": "Class Blog 1",
    "section": "",
    "text": "IPUMS USA website\nA PDF containing screenshots of the selected variables on the IPUMS HEALTH SURVEY website\n*Through these variables names, look for the corresponding variable name in the first link and you see the specific description of each variable. But IPUMS cannot distribute users’ selected datasets’ information directly to others."
  },
  {
    "objectID": "posts/2024-03-03-class-blog-1/class-blog-1.html#key-questions-we-want-to-explore-1",
    "href": "posts/2024-03-03-class-blog-1/class-blog-1.html#key-questions-we-want-to-explore-1",
    "title": "Class Blog 1",
    "section": "Key Questions we want to explore",
    "text": "Key Questions we want to explore\nThe main question we want to focus based on this dataset is the relationship between the age of diabetes diagnosis and personal income. And we can also explore other questions related to this topics like how socioeconomic status influences health outcomes, the patients’ current status and other related."
  },
  {
    "objectID": "posts/2024-03-03-class-blog-1/class-blog-1.html#introduction-1",
    "href": "posts/2024-03-03-class-blog-1/class-blog-1.html#introduction-1",
    "title": "Class Blog 1",
    "section": "Introduction",
    "text": "Introduction\nThis dataset is derived from IPUMS Health Surveys. The sources are from the reputable institutions including The Eunice Kennedy Shriver National Institute of Child Health and Human Development, Stat/Transfer, State Health Access Data Assistance Center, and the University of Minnesota, underscoring its credibility. The primary data are derived from the National Health Interview Survey (NHIS) and the Medical Expenditure Panel Survey (MEPS), which collectively offer a rich and comprehensive dataset representative of the U.S. population. This dataset includes a wide range of variables, both numerical and categorical. Numerical variables cover aspects such as the age of diabetes diagnosis, household weight, family income, educational attainment, poverty level, enrollment fees or premiums for Medicaid plans and etc. Categorical variables include race, insurance coverage, diabetic pill consumption, types of diabetes and etc. The dataset’s size is large, containing over 10,000,000 columns and 24 rows. The dataset’s compatibility can allow us to use dplyr, forcats, lubridate and other skills as we learnt in this class to manipulate and visualize, which makes it an excellent resource for applying and expanding upon the analytical skills developed in class. However, several challenges are anticipated in working with this dataset. One issue is the data was not from these two years. This could limit the accuracy of attributing findings to current conditions. Additionally, there are soma self-reported answers in this dataset, which introduces potential biases. But wee think the large sample size may mitigate the impact of individual errors or biases. Technical challenges may arise during the data analysis, particularly in categorizing and analyzing diverse groups within the dataset."
  },
  {
    "objectID": "posts/2024-03-03-class-blog-1/class-blog-1.html#link-1",
    "href": "posts/2024-03-03-class-blog-1/class-blog-1.html#link-1",
    "title": "Class Blog 1",
    "section": "Link",
    "text": "Link\nIPUMS HEALTH SURVEY website\nA PDF containing screenshots of the selected variables on the IPUMS HEALTH SURVEY website"
  },
  {
    "objectID": "posts/2024-03-03-class-blog-1/class-blog-1.html#key-questions-we-want-to-explore-2",
    "href": "posts/2024-03-03-class-blog-1/class-blog-1.html#key-questions-we-want-to-explore-2",
    "title": "Class Blog 1",
    "section": "Key Questions we want to explore",
    "text": "Key Questions we want to explore\nThe main questions we aimed to address in this dataset involve predicting income levels based on the influence of education. Other variables like work class, and hours worked per week on income, and races can also be used to classify different groups and identify demographic patterns related to income disparities ."
  },
  {
    "objectID": "posts/2024-03-03-class-blog-1/class-blog-1.html#introduction-2",
    "href": "posts/2024-03-03-class-blog-1/class-blog-1.html#introduction-2",
    "title": "Class Blog 1",
    "section": "Introduction",
    "text": "Introduction\nThis dataset comes from 1994 Census bureau database, which is very reliable data source. It comprises 32,561 rows and 15 columns, and the columns represent various attributes such as age, work class, final weight (fnlwgt), education level, marital status, occupation, relationship, race, sex, capital gain, capital loss, hours per week worked, native country, and income. Challenges in analyzing this dataset may include handling missing data (especially in the ‘workclass’ and ‘occupation’ columns where “?” is noted) and how to classify and interpret this."
  },
  {
    "objectID": "posts/2024-03-03-class-blog-1/class-blog-1.html#link-2",
    "href": "posts/2024-03-03-class-blog-1/class-blog-1.html#link-2",
    "title": "Class Blog 1",
    "section": "Link",
    "text": "Link\nThe Kaggle link\nThe original dataset comes from the U.S. Census Bureau"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team 9. The members of this team are below."
  },
  {
    "objectID": "about.html#guo-dingyu",
    "href": "about.html#guo-dingyu",
    "title": "About",
    "section": "Guo, Dingyu",
    "text": "Guo, Dingyu\nkevguo@bu.edu My name is Dingyu Guo, I’m a senior studnet major in Econ and Math. I’m from Beijing, China my github link: https://github.com/kevguo123"
  },
  {
    "objectID": "about.html#suh-edwin-jiho",
    "href": "about.html#suh-edwin-jiho",
    "title": "About",
    "section": "Suh, Edwin, Jiho",
    "text": "Suh, Edwin, Jiho\nHello, my name is Edwin Suh. I am currently a Senior studying Data Science. esuh29@bu.edu https://github.com/esuh29"
  },
  {
    "objectID": "about.html#wang-muxi",
    "href": "about.html#wang-muxi",
    "title": "About",
    "section": "Wang, Muxi",
    "text": "Wang, Muxi\nmwang85@bu.edu https://github.com/muxwang\nHi, my name is Muxi Wang and I am a bioinformatics student at BU."
  },
  {
    "objectID": "about.html#wei-xin",
    "href": "about.html#wei-xin",
    "title": "About",
    "section": "Wei, Xin",
    "text": "Wei, Xin\nricwei@bu.edu"
  },
  {
    "objectID": "about.html#zhu-yating",
    "href": "about.html#zhu-yating",
    "title": "About",
    "section": "Zhu, Yating",
    "text": "Zhu, Yating\nytzhu@bu.edu\nmy github link: https://github.com/yatingzhuzz?tab=repositories\nHello everyone! I’m Yating Zhu, majoring in Math and minoring in Economics. I am a junior. And I am from shanghai, chian. Nice to connect with you all!\n\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.Rmd.\nThink of this page as your 538/Upshot style article. This means that you should try to tell a story through the data and your analysis. Read articles from those sites and similar sites to get a feeling for what they are like. Try to write in the style of a news or popular article. Importantly, this pge should be geared towards the general public. You shouldn’t assume the reader understands how to interpret a linear regression. Focus on interpretation and visualizations."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nInteractive\nYou will also be required to make an interactive dashboard like this one.\nYour Big Data page should include a link to an interactive dashboard. The dashboard should be created either using Shiny or FlexDashboard (or another tool with professor’s approval). This interactive component should in some way support your thesis from your big picture page. Good interactives often provide both high-level understanding of the data while allowing a user to investigate specific scenarios, observations, subgroups, etc.\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions from the Big Picture? Plotly with default hover text will get no credit. Be creative!\n\n\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  }
]